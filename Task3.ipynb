{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T23:54:39.881240Z",
     "start_time": "2021-04-18T23:54:39.868301Z"
    }
   },
   "source": [
    "- 学习特征工程的基本概念\n",
    "- 学习topline代码的特征工程构造方法，实现构建有意义的特征工程\n",
    "- 完成相应学习打卡任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T23:54:51.147374Z",
     "start_time": "2021-04-18T23:54:51.140453Z"
    }
   },
   "source": [
    "## 内容介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@[TOC]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征工程大体可分为3部分，特征构建、特征提取和特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T23:56:47.596769Z",
     "start_time": "2021-04-18T23:56:47.590166Z"
    }
   },
   "source": [
    "### 特征构建\n",
    "+ 探索性数据分析\n",
    "+ 数值特征\n",
    "+ 类别特征\n",
    "+ 时间特征\n",
    "+ 文本特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:02.239426Z",
     "start_time": "2021-04-20T00:38:59.910320Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "\n",
    "import geopandas as gpd\n",
    "# import lightgbm as lgb\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from gensim.models import FastText, Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pyproj import Proj\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:02.579543Z",
     "start_time": "2021-04-20T00:39:02.502659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7000 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# 不直接对DataFrame做append操作，提升运行速度\n",
    "def get_data(file_path,max_lines = 2000):\n",
    "    paths = os.listdir(file_path)\n",
    "    tmp = []\n",
    "    for t in tqdm(range(len(paths))):\n",
    "        if len(tmp) > max_lines:break\n",
    "            \n",
    "        p = paths[t]\n",
    "        with open('{}/{}'.format(file_path, p), encoding='utf-8') as f:\n",
    "            next(f)\n",
    "            for line in f.readlines():\n",
    "                tmp.append(line.strip().split(','))\n",
    "                if len(tmp) > max_lines:break\n",
    "                    \n",
    "    tmp_df = pd.DataFrame(tmp)\n",
    "    tmp_df.columns = ['渔船ID', 'x', 'y', '速度', '方向', 'time', 'type']\n",
    "    return tmp_df\n",
    "data_path = '../team-learning-data-mining-master/wisdomOcean/data/'\n",
    "TRAIN_PATH = f\"{data_path}/hy_round1_train_20200102/\"\n",
    "# 采样数据行数\n",
    "max_lines = 3000\n",
    "df = get_data(TRAIN_PATH,max_lines=max_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:02.921086Z",
     "start_time": "2021-04-20T00:39:02.858838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v</th>\n",
       "      <th>dir</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6966</td>\n",
       "      <td>6.265902e+06</td>\n",
       "      <td>5.279254e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>306</td>\n",
       "      <td>1900-11-06 23:58:16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6966</td>\n",
       "      <td>6.265902e+06</td>\n",
       "      <td>5.279254e+06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-06 23:48:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6966</td>\n",
       "      <td>6.265902e+06</td>\n",
       "      <td>5.279254e+06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-06 23:38:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6966</td>\n",
       "      <td>6.265902e+06</td>\n",
       "      <td>5.279254e+06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-06 23:28:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6966</td>\n",
       "      <td>6.265902e+06</td>\n",
       "      <td>5.279254e+06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>130</td>\n",
       "      <td>1900-11-06 23:08:17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id             x             y     v  dir                time  label\n",
       "0  6966  6.265902e+06  5.279254e+06  0.11  306 1900-11-06 23:58:16      1\n",
       "1  6966  6.265902e+06  5.279254e+06  0.00    0 1900-11-06 23:48:21      1\n",
       "2  6966  6.265902e+06  5.279254e+06  0.00    0 1900-11-06 23:38:19      1\n",
       "3  6966  6.265902e+06  5.279254e+06  0.00    0 1900-11-06 23:28:36      1\n",
       "4  6966  6.265902e+06  5.279254e+06  0.32  130 1900-11-06 23:08:17      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基本预处理\n",
    "label_dict1 = {'拖网': 0, '围网': 1, '刺网': 2}\n",
    "label_dict2 = {0: '拖网', 1: '围网', 2: '刺网'}\n",
    "name_dict = {'渔船ID': 'id', '速度': 'v', '方向': 'dir', 'type': 'label'}\n",
    "\n",
    "df.rename(columns = name_dict, inplace = True)\n",
    "df['label'] = df['label'].map(label_dict1)\n",
    "cols = ['x','y','v']\n",
    "for col in cols:\n",
    "    df[col] = df[col].astype('float')\n",
    "df['dir'] = df['dir'].astype('int')\n",
    "df['time'] = pd.to_datetime(df['time'], format='%m%d %H:%M:%S')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:03.281506Z",
     "start_time": "2021-04-20T00:39:03.265453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3001 entries, 0 to 3000\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   id      3001 non-null   object        \n",
      " 1   x       3001 non-null   float64       \n",
      " 2   y       3001 non-null   float64       \n",
      " 3   v       3001 non-null   float64       \n",
      " 4   dir     3001 non-null   int64         \n",
      " 5   time    3001 non-null   datetime64[ns]\n",
      " 6   label   3001 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(2), object(1)\n",
      "memory usage: 164.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 赛题特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 距离特征\n",
    "\n",
    "    - 构造各点的(x、y)坐标与特定点(6165599,5202660)的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:05.809071Z",
     "start_time": "2021-04-20T00:39:05.778622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    126203.102299\n",
       "1    126203.102299\n",
       "2    126203.102299\n",
       "3    126203.102299\n",
       "4    126203.102299\n",
       "Name: base_dis_diff, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x_dis_diff'] = (df['x'] - 6165599).abs()\n",
    "df['y_dis_diff'] = (df['y'] - 5202660).abs()\n",
    "df['base_dis_diff'] = ((df['x_dis_diff']**2)+(df['y_dis_diff']**2))**0.5    \n",
    "del df['x_dis_diff'],df['y_dis_diff'] \n",
    "df['base_dis_diff'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 时间特征\n",
    "    - 对时间，小时进行白天、黑天进行划分，5-20为白天1，其余为黑天0\n",
    "    - 周\n",
    "    - 季度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:08.576868Z",
     "start_time": "2021-04-20T00:39:08.558189Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df['date'] = df['time'].dt.date\n",
    "df['hour'] = df['time'].dt.hour\n",
    "df['month'] = df['time'].dt.month\n",
    "df['weekday'] = df['time'].dt.weekday\n",
    "df['day_nig'] = 0\n",
    "df.loc[(df['hour'] > 5) & (df['hour'] < 20),'day_nig'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 动态特征\n",
    "    - 动态速度，速度变化，角度变化，xy相似性等特征\n",
    "    - 统计每个ship的对应速度等级的个数\n",
    "    - 方位进行16均分\n",
    "    - 统计速度为0的个数，以及速度不为0的统计量\n",
    "    - 加入x，v，d，y的中位数和各种位数\n",
    "    - 以ship、time为主键进行排序\n",
    "        - 通过shift求相邻差异值,时间差分，角度差分，x， y差分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:10.070495Z",
     "start_time": "2021-04-20T00:39:10.028057Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = df.copy()\n",
    "temp.rename(columns={'id':'ship','dir':'d'},inplace=True)\n",
    "\n",
    "# 给速度一个等级\n",
    "# def v_cut(v):\n",
    "#     if v < 0.1:\n",
    "#         return 0\n",
    "#     elif v < 0.5:\n",
    "#         return 1\n",
    "#     elif v < 1:\n",
    "#         return 2\n",
    "#     elif v < 2.5:\n",
    "#         return 3\n",
    "#     elif v < 5:\n",
    "#         return 4\n",
    "#     elif v < 10:\n",
    "#         return 5\n",
    "#     elif v < 20:\n",
    "#         return 5\n",
    "#     else:\n",
    "#         return 6\n",
    "\n",
    "\n",
    "# 统计每个ship的对应速度等级的个数\n",
    "def get_v_fea(df):\n",
    "\n",
    "#     df['v_cut'] = df['v'].apply(lambda x: v_cut(x))\n",
    "    bins = [-np.inf,0.1,0.5,1,2.5,5,20,np.inf]\n",
    "    df['v_cut'] = pd.cut(df['v'],bins = bins,labels = np.arange(len(bins)-1)).fillna(6)\n",
    "#     tmp = df.groupby(['ship', 'v_cut'], as_index=False)['v_cut'].agg({'v_cut_count': 'count'})\n",
    "    tmp = temp.groupby(['ship', 'v_cut']).agg({'x': 'count'}).reset_index().rename(columns = {'x':'v_cut_count'})\n",
    "    # 通过pivot构建透视表\n",
    "    tmp = tmp.pivot_table(index='ship', columns='v_cut', values='v_cut_count')\n",
    "\n",
    "    new_col_nm = ['v_cut_' + str(col) for col in tmp.columns.tolist()]\n",
    "    tmp.columns = new_col_nm\n",
    "    tmp = tmp.reset_index()  # 把index恢复成data\n",
    "\n",
    "    return tmp\n",
    "\n",
    "c1 = get_v_fea(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:11.198362Z",
     "start_time": "2021-04-20T00:39:11.167312Z"
    }
   },
   "outputs": [],
   "source": [
    "# 方位进行16均分\n",
    "def add_direction(df):\n",
    "#     df['d16'] = df['d'].apply(lambda x: int((x / 22.5) + 0.5) % 16 if not np.isnan(x) else np.nan)\n",
    "#     df['d16'] = (df['d']/ 22.5 +0.5)% 16//1\n",
    "    bins = np.arange(17)*382.5/17\n",
    "    df['d16'] = pd.cut(df['d'],bins = bins,labels = np.arange(len(bins)-1))\n",
    "    return df\n",
    "def get_d_cut_count_fea(df):\n",
    "    df = add_direction(df)\n",
    "#     print(df.columns)\n",
    "    tmp = df.groupby(['ship', 'd16']).agg({'x': 'count'}).reset_index().rename(columns = {'x':'d16_count'})\n",
    "    tmp = tmp.pivot(index='ship', columns='d16', values='d16_count')\n",
    "    new_col_nm = ['d16_' + str(col) for col in tmp.columns.tolist()]\n",
    "    tmp.columns = new_col_nm\n",
    "    tmp = tmp.reset_index()\n",
    "    return tmp\n",
    "\n",
    "c2 = get_d_cut_count_fea(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:12.552352Z",
     "start_time": "2021-04-20T00:39:12.512123Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_v0_fea(df):\n",
    "    # 统计速度为0的个数，以及速度不为0的统计量\n",
    "    df_zero_count = df.query(\"v==0\")[['ship', 'v']].groupby('ship', as_index=False)['v'].agg(\n",
    "        {'num_zero_v': 'count'})\n",
    "    df_not_zero_agg = df.query(\"v!=0\")[['ship', 'v']].groupby('ship', as_index=False)['v'].agg(\n",
    "        {'v_max_drop_0': 'max',\n",
    "         'v_min_drop_0': 'min',\n",
    "         'v_mean_drop_0': 'mean',\n",
    "         'v_std_drop_0': 'std',\n",
    "         'v_median_drop_0': 'median',\n",
    "         'v_skew_drop_0': 'skew'})\n",
    "    tmp = df_zero_count.merge(df_not_zero_agg, on='ship', how='left')\n",
    "\n",
    "    return tmp\n",
    "\n",
    "c3 = get_v0_fea(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:13.698069Z",
     "start_time": "2021-04-20T00:39:13.557036Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_percentiles_fea(df_raw):\n",
    "    key = ['x', 'y', 'v', 'd']\n",
    "    temp = df_raw[['ship']].drop_duplicates('ship')\n",
    "    for i in range(len(key)):\n",
    "        # 加入x，v，d，y的中位数和各种位数\n",
    "        tmp_dscb = df_raw.groupby('ship')[key[i]].describe(\n",
    "            percentiles=[0.05] + [ii / 1000 for ii in range(125, 1000, 125)] + [0.95])\n",
    "        raw_col_nm = tmp_dscb.columns.tolist()\n",
    "        new_col_nm = [key[i] + '_' + col for col in raw_col_nm]\n",
    "        tmp_dscb.columns = new_col_nm\n",
    "        tmp_dscb = tmp_dscb.reset_index()\n",
    "        # 删掉多余的统计特征\n",
    "        tmp_dscb = tmp_dscb.drop([f'{key[i]}_count', f'{key[i]}_mean', f'{key[i]}_std',\n",
    "                                  f'{key[i]}_min', f'{key[i]}_max'], axis=1)\n",
    "\n",
    "        temp = temp.merge(tmp_dscb, on='ship', how='left')\n",
    "    return temp\n",
    "\n",
    "c4 = get_percentiles_fea(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:15.095565Z",
     "start_time": "2021-04-20T00:39:14.851487Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_d_change_rate_fea(df):\n",
    "    import math\n",
    "    import time\n",
    "    temp = df.copy()\n",
    "    # 以ship、time为主键进行排序\n",
    "    temp.sort_values(['ship', 'time'], ascending=True, inplace=True)\n",
    "    # 通过shift求相邻差异值，注意学习.shift(-1,1)的含义\n",
    "    temp['timenext'] = temp.groupby('ship')['time'].shift(-1)\n",
    "    temp['ynext'] = temp.groupby('ship')['y'].shift(-1)\n",
    "    temp['xnext'] = temp.groupby('ship')['x'].shift(-1)\n",
    "    # 将shift得到的差异量进行填充，为什么会有空值NaN？\n",
    "    # 因为shift的起始位置是没法比较的，故用空值来代替\n",
    "    temp['ynext'] = temp['ynext'].fillna(method='ffill')\n",
    "    temp['xnext'] = temp['xnext'].fillna(method='ffill')\n",
    "    # 这里笔者的理解是ynext/xnext，而不需要减去y和x，因为ynext和xnext本身就是偏移量了\n",
    "    temp['angle_next'] = (temp['ynext'] - temp['y']) / (temp['xnext'] - temp['x'])\n",
    "    temp['angle_next'] = np.arctan(temp['angle_next']) / math.pi * 180\n",
    "    temp['angle_next_next'] = temp.groupby('ship')['angle_next'].shift(-1)\n",
    "    \n",
    "    temp['timediff'] = np.abs(temp['timenext'] - temp['time'])\n",
    "    temp['timediff'] = temp['timediff'].fillna(method='ffill')\n",
    "    \n",
    "    temp['hc_xy'] = abs(temp['angle_next_next'] - temp['angle_next'])\n",
    "    # 对于hc_xy这列的值>180度的，进行修改成360度求差，仅考虑与水平线的角度\n",
    "    temp.loc[temp['hc_xy'] > 180, 'hc_xy'] = (360 - temp.loc[temp['hc_xy'] > 180, 'hc_xy'])\n",
    "    temp['hc_xy_s'] = temp.apply(lambda x: x['hc_xy'] / x['timediff'].total_seconds(), axis=1)\n",
    "\n",
    "    temp['d_next'] = temp.groupby('ship')['d'].shift(-1)\n",
    "    temp['hc_d'] = abs(temp['d_next'] - temp['d'])\n",
    "    temp.loc[temp['hc_d'] > 180, 'hc_d'] = 360 - temp.loc[temp['hc_d'] > 180, 'hc_d']\n",
    "    temp['hc_d_s'] = temp.apply(lambda x: x['hc_d'] / x['timediff'].total_seconds(), axis=1)\n",
    "\n",
    "    temp1 = temp[['ship', 'hc_xy_s', 'hc_d_s']]\n",
    "#     xy_d_rate = temp1.groupby('ship')['hc_xy_s'].agg({'hc_xy_s_max': 'max',})\n",
    "#     xy_d_rate = xy_d_rate.reset_index()\n",
    "#     d_d_rate = temp1.groupby('ship')['hc_d_s'].agg({'hc_d_s_max': 'max',})\n",
    "#     d_d_rate = d_d_rate.reset_index()\n",
    "#     tmp = xy_d_rate.merge(d_d_rate, on='ship', how='left')\n",
    "    d_d_rate = temp1.groupby('ship').agg({'hc_xy_s':'max','hc_d_s':'max'}).reset_index()\n",
    "    d_d_rate.rename(columns = {'hc_xy_s':'hc_xy_s_max','hc_d_s':'hc_d_s_max'})\n",
    "\n",
    "    return d_d_rate\n",
    "\n",
    "c5 = get_d_change_rate_fea(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:16.137736Z",
     "start_time": "2021-04-20T00:39:16.083671Z"
    }
   },
   "outputs": [],
   "source": [
    "f1 = temp.merge(c1,on='ship',how='left')\n",
    "f1 = f1.merge(c2,on='ship',how='left')\n",
    "f1 = f1.merge(c3,on='ship',how='left')\n",
    "f1 = f1.merge(c4,on='ship',how='left')\n",
    "f1 = f1.merge(c5,on='ship',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分箱特征\n",
    "##### v、x、y的分箱特征\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:22.686905Z",
     "start_time": "2021-04-20T00:39:22.460395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_bin</th>\n",
       "      <th>x_bin1</th>\n",
       "      <th>x_bin2</th>\n",
       "      <th>x_bin1_count</th>\n",
       "      <th>x_bin2_count</th>\n",
       "      <th>x_bin1_id_nunique</th>\n",
       "      <th>x_bin2_id_nunique</th>\n",
       "      <th>y_bin1</th>\n",
       "      <th>y_bin2</th>\n",
       "      <th>y_bin1_count</th>\n",
       "      <th>...</th>\n",
       "      <th>y_bin1_id_nunique</th>\n",
       "      <th>y_bin2_id_nunique</th>\n",
       "      <th>x_y_bin1</th>\n",
       "      <th>x_bin1_y_bin1_count</th>\n",
       "      <th>x_y_bin2</th>\n",
       "      <th>x_bin2_y_bin2_count</th>\n",
       "      <th>x_y_max</th>\n",
       "      <th>y_x_max</th>\n",
       "      <th>x_y_min</th>\n",
       "      <th>y_x_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>302</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>304</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49224.816068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>302</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>304</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49224.816068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>302</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>304</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49224.816068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>302</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>304</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49224.816068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>302</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>304</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49224.816068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  v_bin x_bin1  x_bin2  x_bin1_count  x_bin2_count  x_bin1_id_nunique  \\\n",
       "0     0      0   626.0           302           345                  1   \n",
       "1     1      0   626.0           302           345                  1   \n",
       "2     1      0   626.0           302           345                  1   \n",
       "3     1      0   626.0           302           345                  1   \n",
       "4     2      0   626.0           302           345                  1   \n",
       "\n",
       "   x_bin2_id_nunique y_bin1  y_bin2  y_bin1_count  ...  y_bin1_id_nunique  \\\n",
       "0                  1      0   527.0           304  ...                  2   \n",
       "1                  1      0   527.0           304  ...                  2   \n",
       "2                  1      0   527.0           304  ...                  2   \n",
       "3                  1      0   527.0           304  ...                  2   \n",
       "4                  1      0   527.0           304  ...                  2   \n",
       "\n",
       "   y_bin2_id_nunique  x_y_bin1  x_bin1_y_bin1_count  x_y_bin2  \\\n",
       "0                  2         0                  302         0   \n",
       "1                  2         0                  302         0   \n",
       "2                  2         0                  302         0   \n",
       "3                  2         0                  302         0   \n",
       "4                  2         0                  302         0   \n",
       "\n",
       "   x_bin2_y_bin2_count  x_y_max       y_x_max  x_y_min  y_x_min  \n",
       "0                  345      0.0 -49224.816068      0.0      0.0  \n",
       "1                  345      0.0 -49224.816068      0.0      0.0  \n",
       "2                  345      0.0 -49224.816068      0.0      0.0  \n",
       "3                  345      0.0 -49224.816068      0.0      0.0  \n",
       "4                  345      0.0 -49224.816068      0.0      0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v、x、y的分箱特征\n",
    "pre_cols = df.columns\n",
    "\n",
    "df['v_bin'] = pd.qcut(df['v'], 200, duplicates='drop') # 速度进行 200分位数分箱\n",
    "df['v_bin'] = df['v_bin'].map(dict(zip(df['v_bin'].unique(), range(df['v_bin'].nunique())))) # 分箱后映射编码\n",
    "for f in ['x', 'y']:\n",
    "    df[f + '_bin1'] = pd.qcut(df[f], 1000, duplicates='drop') # x,y位置分箱1000\n",
    "    df[f + '_bin1'] = df[f + '_bin1'].map(dict(zip(df[f + '_bin1'].unique(), range(df[f + '_bin1'].nunique()))))#编码\n",
    "    df[f + '_bin2'] = df[f] // 10000 # 取整操作\n",
    "    df[f + '_bin1_count'] = df[f + '_bin1'].map(df[f + '_bin1'].value_counts()) #x,y不同分箱的数量映射\n",
    "    df[f + '_bin2_count'] = df[f + '_bin2'].map(df[f + '_bin2'].value_counts()) #数量映射\n",
    "    df[f + '_bin1_id_nunique'] = df.groupby(f + '_bin1')['id'].transform('nunique')#基于分箱1 id数量映射\n",
    "    df[f + '_bin2_id_nunique'] = df.groupby(f + '_bin2')['id'].transform('nunique')#基于分箱2 id数量映射\n",
    "    \n",
    "for i in [1, 2]:\n",
    "    # 特征交叉x_bin1（2）,y_bin1（2） 形成类别 统计每类数量映射到列  \n",
    "    df['x_y_bin{}'.format(i)] = df['x_bin{}'.format(i)].astype('str') + '_' + df['y_bin{}'.format(i)].astype('str')\n",
    "    df['x_y_bin{}'.format(i)] = df['x_y_bin{}'.format(i)].map(\n",
    "        dict(zip(df['x_y_bin{}'.format(i)].unique(), range(df['x_y_bin{}'.format(i)].nunique())))\n",
    "    )\n",
    "    df['x_bin{}_y_bin{}_count'.format(i, i)] = df['x_y_bin{}'.format(i)].map(df['x_y_bin{}'.format(i)].value_counts())\n",
    "for stat in ['max', 'min']:\n",
    "    # 统计x_bin1 y_bin1的最大最小值\n",
    "    df['x_y_{}'.format(stat)] = df['y'] - df.groupby('x_bin1')['y'].transform(stat)\n",
    "    df['y_x_{}'.format(stat)] = df['x'] - df.groupby('y_bin1')['x'].transform(stat)\n",
    "\n",
    "new_cols = [i for i in df.columns if i not in pre_cols]\n",
    "df[new_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 将x、y进行分箱并构造区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:41.349196Z",
     "start_time": "2021-04-20T00:39:41.325580Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def traj_to_bin(traj=None, x_min=12031967.16239096, x_max=14226964.881853,\n",
    "                y_min=1623579.449434373, y_max=4689471.1780792,\n",
    "                row_bins=4380, col_bins=3136):\n",
    "\n",
    "    # Establish bins on x direction and y direction\n",
    "    x_bins = np.linspace(x_min, x_max, endpoint=True, num=col_bins + 1)\n",
    "    y_bins = np.linspace(y_min, y_max, endpoint=True, num=row_bins + 1)\n",
    "\n",
    "    # Determine each x coordinate belong to which bin\n",
    "    traj.sort_values(by='x', inplace=True)\n",
    "    x_res = np.zeros((len(traj), ))\n",
    "    j = 0\n",
    "    for i in range(1, col_bins + 1):\n",
    "        low, high = x_bins[i-1], x_bins[i]\n",
    "        while( j < len(traj)):\n",
    "            # low - 0.001 for numeric stable.\n",
    "            if (traj[\"x\"].iloc[j] <= high) & (traj[\"x\"].iloc[j] > low - 0.001):\n",
    "                x_res[j] = i\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "    traj[\"x_grid\"] = x_res\n",
    "    traj[\"x_grid\"] = traj[\"x_grid\"].astype(int)\n",
    "    traj[\"x_grid\"] = traj[\"x_grid\"].apply(str)\n",
    "\n",
    "    # Determine each y coordinate belong to which bin\n",
    "    traj.sort_values(by='y', inplace=True)\n",
    "    y_res = np.zeros((len(traj), ))\n",
    "    j = 0\n",
    "    for i in range(1, row_bins + 1):\n",
    "        low, high = y_bins[i-1], y_bins[i]\n",
    "        while( j < len(traj)):\n",
    "            # low - 0.001 for numeric stable.\n",
    "            if (traj[\"y\"].iloc[j] <= high) & (traj[\"y\"].iloc[j] > low - 0.001):\n",
    "                y_res[j] = i\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "    traj[\"y_grid\"] = y_res\n",
    "    traj[\"y_grid\"] = traj[\"y_grid\"].astype(int)\n",
    "    traj[\"y_grid\"] = traj[\"y_grid\"].apply(str)\n",
    "\n",
    "    # Determine which bin each coordinate belongs to.\n",
    "    traj[\"no_bin\"] = [i + \"_\" + j for i, j in zip(\n",
    "        traj[\"x_grid\"].values.tolist(), traj[\"y_grid\"].values.tolist())]\n",
    "    traj.sort_values(by='time', inplace=True)\n",
    "    return traj\n",
    "\n",
    "bin_size = 800\n",
    "col_bins = int((14226964.881853 - 12031967.16239096) / bin_size)\n",
    "row_bins = int((4689471.1780792 - 1623579.449434373) / bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:39:48.686055Z",
     "start_time": "2021-04-20T00:39:48.290352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_grid</th>\n",
       "      <th>y_grid</th>\n",
       "      <th>no_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>0</td>\n",
       "      <td>4238</td>\n",
       "      <td>0_4238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0</td>\n",
       "      <td>4239</td>\n",
       "      <td>0_4239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>0</td>\n",
       "      <td>4239</td>\n",
       "      <td>0_4239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0</td>\n",
       "      <td>4240</td>\n",
       "      <td>0_4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>0</td>\n",
       "      <td>4241</td>\n",
       "      <td>0_4241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_grid y_grid  no_bin\n",
       "2320      0      0     0_0\n",
       "1200      0      0     0_0\n",
       "2319      0      0     0_0\n",
       "1199      0      0     0_0\n",
       "2318      0      0     0_0\n",
       "...     ...    ...     ...\n",
       "1205      0   4238  0_4238\n",
       "1204      0   4239  0_4239\n",
       "1203      0   4239  0_4239\n",
       "1202      0   4240  0_4240\n",
       "1201      0   4241  0_4241\n",
       "\n",
       "[3001 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_cols = df.columns\n",
    "# 特征x_grid,y_grid,no_bin\n",
    "df = traj_to_bin(df)\n",
    "\n",
    "new_cols = [i for i in df.columns if i not in pre_cols]\n",
    "df[new_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计特征\n",
    "##### count计数值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:07.522445Z",
     "start_time": "2021-04-20T00:40:07.506951Z"
    }
   },
   "outputs": [],
   "source": [
    "# def find_save_visit_count_table(traj_data_df=None, bin_to_coord_df=None):\n",
    "#     \"\"\"Find and save the visit frequency of each bin.\"\"\"\n",
    "#     visit_count_df = traj_data_df.groupby([\"no_bin\"]).agg({'x':'count'}).reset_index()[[\"no_bin\", \"x\"]].rename({\"x\":\"visit_count\"})\n",
    "# #     visit_count_df = visit_count_df[[\"no_bin\", \"x\"]]\n",
    "# #     visit_count_df.rename({\"x\":\"visit_count\"}, axis=1, inplace=True)\n",
    "#     return visit_count_df\n",
    "\n",
    "# def find_save_unique_visit_count_table(traj_data_df=None, bin_to_coord_df=None):\n",
    "#     \"\"\"Find and save the unique boat visit count of each bin.\"\"\"\n",
    "#     unique_boat_count_df = traj_data_df.groupby([\"no_bin\"]).agg({'id':'nunique'}).reset_index().rename({\"id\":\"visit_boat_count\"})\n",
    "# #     unique_boat_count_df.rename({\"id\":\"visit_boat_count\"}, axis=1, inplace=True)\n",
    "\n",
    "#     unique_boat_count_df_save = pd.merge(bin_to_coord_df, unique_boat_count_df,\n",
    "#                                          on=\"no_bin\", how=\"left\")\n",
    "#     return unique_boat_count_df\n",
    "\n",
    "# traj_df = df[[\"id\",\"x\", \"y\",'time',\"no_bin\"]]\n",
    "# bin_to_coord_df = traj_df.groupby([\"no_bin\"]).median().reset_index()\n",
    "def find_save_visit_count_table(traj_data_df=None, bin_to_coord_df=None):\n",
    "    \"\"\"Find and save the visit frequency of each bin.\"\"\"\n",
    "    visit_count_df = traj_data_df.groupby([\"no_bin\"]).count().reset_index()\n",
    "    visit_count_df = visit_count_df[[\"no_bin\", \"x\"]]\n",
    "    visit_count_df.rename({\"x\":\"visit_count\"}, axis=1, inplace=True)\n",
    "    return visit_count_df\n",
    "\n",
    "def find_save_unique_visit_count_table(traj_data_df=None, bin_to_coord_df=None):\n",
    "    \"\"\"Find and save the unique boat visit count of each bin.\"\"\"\n",
    "    unique_boat_count_df = traj_data_df.groupby([\"no_bin\"])[\"id\"].nunique().reset_index()\n",
    "    unique_boat_count_df.rename({\"id\":\"visit_boat_count\"}, axis=1, inplace=True)\n",
    "\n",
    "    unique_boat_count_df_save = pd.merge(bin_to_coord_df, unique_boat_count_df,\n",
    "                                         on=\"no_bin\", how=\"left\")\n",
    "    return unique_boat_count_df\n",
    "\n",
    "traj_df = df[[\"id\",\"x\", \"y\",'time',\"no_bin\"]]\n",
    "bin_to_coord_df = traj_df.groupby([\"no_bin\"]).median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:12.160696Z",
     "start_time": "2021-04-20T00:40:12.105623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_count</th>\n",
       "      <th>visit_boat_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2705</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2705</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2705</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2705</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_count  visit_boat_count\n",
       "0         2705                 7\n",
       "1         2705                 7\n",
       "2         2705                 7\n",
       "3         2705                 7\n",
       "4         2705                 7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_cols = df.columns\n",
    "\n",
    "# DataFrame tmp for finding POIs\n",
    "visit_count_df = find_save_visit_count_table(\n",
    "    traj_df, bin_to_coord_df)\n",
    "unique_boat_count_df = find_save_unique_visit_count_table(\n",
    "    traj_df, bin_to_coord_df)\n",
    "\n",
    "# # 特征'visit_count','visit_boat_count'\n",
    "df = df.merge(visit_count_df,on='no_bin',how='left')\n",
    "df = df.merge(unique_boat_count_df,on='no_bin',how='left')\n",
    "\n",
    "new_cols = [i for i in df.columns if i not in pre_cols]\n",
    "df[new_cols].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### shift偏移量特征\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:20.585923Z",
     "start_time": "2021-04-20T00:40:20.525381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_prev_diff</th>\n",
       "      <th>x_next_diff</th>\n",
       "      <th>x_prev_next_diff</th>\n",
       "      <th>y_prev_diff</th>\n",
       "      <th>y_next_diff</th>\n",
       "      <th>y_prev_next_diff</th>\n",
       "      <th>dist_move_prev</th>\n",
       "      <th>dist_move_next</th>\n",
       "      <th>dist_move_prev_next</th>\n",
       "      <th>dist_move_prev_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2379.515712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>928.136470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2554.120657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2379.515712</td>\n",
       "      <td>-2289.136947</td>\n",
       "      <td>-4668.652659</td>\n",
       "      <td>-928.13647</td>\n",
       "      <td>1261.126019</td>\n",
       "      <td>2189.262489</td>\n",
       "      <td>2554.120657</td>\n",
       "      <td>2613.539133</td>\n",
       "      <td>5156.470488</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_prev_diff  x_next_diff  x_prev_next_diff  y_prev_diff  y_next_diff  \\\n",
       "0          NaN     0.000000               NaN          NaN     0.000000   \n",
       "1          NaN -2379.515712               NaN          NaN   928.136470   \n",
       "2     0.000000     0.000000          0.000000      0.00000     0.000000   \n",
       "3  2379.515712 -2289.136947      -4668.652659   -928.13647  1261.126019   \n",
       "4     0.000000     0.000000          0.000000      0.00000     0.000000   \n",
       "\n",
       "   y_prev_next_diff  dist_move_prev  dist_move_next  dist_move_prev_next  \\\n",
       "0               NaN             NaN        0.000000                  NaN   \n",
       "1               NaN             NaN     2554.120657                  NaN   \n",
       "2          0.000000        0.000000        0.000000             0.000000   \n",
       "3       2189.262489     2554.120657     2613.539133          5156.470488   \n",
       "4          0.000000        0.000000        0.000000             0.000000   \n",
       "\n",
       "   dist_move_prev_bin  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 1.0  \n",
       "3                 2.0  \n",
       "4                 1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shift偏移量特征\n",
    "pre_cols = df.columns\n",
    "\n",
    "g = df.groupby('id')\n",
    "for f in ['x', 'y']:\n",
    "    #对x,y坐标进行时间平移 1 -1 2\n",
    "    df[f + '_prev_diff'] = df[f] - g[f].shift(1)\n",
    "    df[f + '_next_diff'] = df[f] - g[f].shift(-1)\n",
    "    df[f + '_prev_next_diff'] = g[f].shift(1) - g[f].shift(-1)\n",
    "    ## 三角形求解上时刻1距离  下时刻-1距离 2距离 \n",
    "df['dist_move_prev'] = np.sqrt(np.square(df['x_prev_diff']) + np.square(df['y_prev_diff']))\n",
    "df['dist_move_next'] = np.sqrt(np.square(df['x_next_diff']) + np.square(df['y_next_diff']))\n",
    "df['dist_move_prev_next'] = np.sqrt(np.square(df['x_prev_next_diff']) + np.square(df['y_prev_next_diff']))\n",
    "df['dist_move_prev_bin'] = pd.qcut(df['dist_move_prev'], 50, duplicates='drop')# 2时刻距离等频分箱50\n",
    "df['dist_move_prev_bin'] = df['dist_move_prev_bin'].map(\n",
    "    dict(zip(df['dist_move_prev_bin'].unique(), range(df['dist_move_prev_bin'].nunique())))\n",
    ") #上一时刻映射编码\n",
    "\n",
    "new_cols = [i for i in df.columns if i not in pre_cols]\n",
    "df[new_cols].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:32.236440Z",
     "start_time": "2021-04-20T00:40:32.032826Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_cols = df.columns\n",
    "\n",
    "def start(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def end(x):\n",
    "    try:\n",
    "        return x[-1]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def mode(x):\n",
    "    try:\n",
    "        return pd.Series(x).value_counts().index[0]\n",
    "    except:\n",
    "        return None\n",
    "for f in ['dist_move_prev_bin', 'v_bin']:\n",
    "    # 上一时刻类别 速度类别映射处理\n",
    "    df[f + '_sen'] = df['id'].map(df.groupby('id')[f].agg(lambda x: ','.join(x.astype(str))))\n",
    "    # 一系列基本统计量特征 每列执行相应的操作\n",
    "g = df.groupby('id').agg({\n",
    "    'id': ['count'], \n",
    "    'x_bin1': [mode], \n",
    "    'y_bin1': [mode], \n",
    "    'x_bin2': [mode], \n",
    "    'y_bin2': [mode], \n",
    "    'x_y_bin1': [mode],\n",
    "    'x': ['mean', 'max', 'min', 'std', np.ptp, start, end],\n",
    "    'y': ['mean', 'max', 'min', 'std', np.ptp, start, end],\n",
    "    'v': ['mean', 'max', 'min', 'std', np.ptp], \n",
    "    'dir': ['mean'],\n",
    "    'x_bin1_count': ['mean'], \n",
    "    'y_bin1_count': ['mean', 'max', 'min'],\n",
    "    'x_bin2_count': ['mean', 'max', 'min'], \n",
    "    'y_bin2_count': ['mean', 'max', 'min'],\n",
    "    'x_bin1_y_bin1_count': ['mean', 'max', 'min'],\n",
    "    'dist_move_prev': ['mean', 'max', 'std', 'min', 'sum'],\n",
    "    'x_y_min': ['mean', 'min'], \n",
    "    'y_x_min': ['mean', 'min'],\n",
    "    'x_y_max': ['mean', 'min'], \n",
    "    'y_x_max': ['mean', 'min'],\n",
    "}).reset_index()\n",
    "g.columns = ['_'.join(col).strip() for col in g.columns] #提取列名\n",
    "g.rename(columns={'id_': 'id'}, inplace=True) #重命名id_\n",
    "cols = [f for f in g.keys() if f != 'id'] #特征列名提取    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:34.334641Z",
     "start_time": "2021-04-20T00:40:34.279290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_move_prev_bin_sen</th>\n",
       "      <th>v_bin_sen</th>\n",
       "      <th>id_count</th>\n",
       "      <th>x_bin1_mode</th>\n",
       "      <th>y_bin1_mode</th>\n",
       "      <th>x_bin2_mode</th>\n",
       "      <th>y_bin2_mode</th>\n",
       "      <th>x_y_bin1_mode</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>x_max</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_move_prev_min</th>\n",
       "      <th>dist_move_prev_sum</th>\n",
       "      <th>x_y_min_mean</th>\n",
       "      <th>x_y_min_min</th>\n",
       "      <th>y_x_min_mean</th>\n",
       "      <th>y_x_min_min</th>\n",
       "      <th>x_y_max_mean</th>\n",
       "      <th>x_y_max_min</th>\n",
       "      <th>y_x_max_mean</th>\n",
       "      <th>y_x_max_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1....</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...</td>\n",
       "      <td>405</td>\n",
       "      <td>430</td>\n",
       "      <td>385</td>\n",
       "      <td>610.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>914</td>\n",
       "      <td>6.111712e+06</td>\n",
       "      <td>6.146439e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167403.635587</td>\n",
       "      <td>3951.751016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.203566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1994.875200</td>\n",
       "      <td>-27993.134668</td>\n",
       "      <td>-5527.254366</td>\n",
       "      <td>-103239.952092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan,2.0,3.0,2.0,2.0,4.0,3.0,2.0,3.0,3.0,4.0,2....</td>\n",
       "      <td>22,20,19,15,68,66,15,66,52,61,18,17,18,17,17,1...</td>\n",
       "      <td>386</td>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "      <td>675.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>221</td>\n",
       "      <td>6.806687e+06</td>\n",
       "      <td>6.965640e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>539855.200175</td>\n",
       "      <td>3285.973541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35750.598766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1703.494682</td>\n",
       "      <td>-46893.002685</td>\n",
       "      <td>-32262.980249</td>\n",
       "      <td>-318563.512015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1....</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...</td>\n",
       "      <td>405</td>\n",
       "      <td>430</td>\n",
       "      <td>385</td>\n",
       "      <td>610.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>914</td>\n",
       "      <td>6.111712e+06</td>\n",
       "      <td>6.146439e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167403.635587</td>\n",
       "      <td>3951.751016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.203566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1994.875200</td>\n",
       "      <td>-27993.134668</td>\n",
       "      <td>-5527.254366</td>\n",
       "      <td>-103239.952092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nan,2.0,3.0,2.0,2.0,4.0,3.0,2.0,3.0,3.0,4.0,2....</td>\n",
       "      <td>22,20,19,15,68,66,15,66,52,61,18,17,18,17,17,1...</td>\n",
       "      <td>386</td>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "      <td>675.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>221</td>\n",
       "      <td>6.806687e+06</td>\n",
       "      <td>6.965640e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>539855.200175</td>\n",
       "      <td>3285.973541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35750.598766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1703.494682</td>\n",
       "      <td>-46893.002685</td>\n",
       "      <td>-32262.980249</td>\n",
       "      <td>-318563.512015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1....</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...</td>\n",
       "      <td>405</td>\n",
       "      <td>430</td>\n",
       "      <td>385</td>\n",
       "      <td>610.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>914</td>\n",
       "      <td>6.111712e+06</td>\n",
       "      <td>6.146439e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167403.635587</td>\n",
       "      <td>3951.751016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.203566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1994.875200</td>\n",
       "      <td>-27993.134668</td>\n",
       "      <td>-5527.254366</td>\n",
       "      <td>-103239.952092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              dist_move_prev_bin_sen  \\\n",
       "0  nan,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1....   \n",
       "1  nan,2.0,3.0,2.0,2.0,4.0,3.0,2.0,3.0,3.0,4.0,2....   \n",
       "2  nan,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1....   \n",
       "3  nan,2.0,3.0,2.0,2.0,4.0,3.0,2.0,3.0,3.0,4.0,2....   \n",
       "4  nan,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1....   \n",
       "\n",
       "                                           v_bin_sen  id_count  x_bin1_mode  \\\n",
       "0  1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...       405          430   \n",
       "1  22,20,19,15,68,66,15,66,52,61,18,17,18,17,17,1...       386           94   \n",
       "2  1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...       405          430   \n",
       "3  22,20,19,15,68,66,15,66,52,61,18,17,18,17,17,1...       386           94   \n",
       "4  1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...       405          430   \n",
       "\n",
       "   y_bin1_mode  x_bin2_mode  y_bin2_mode  x_y_bin1_mode        x_mean  \\\n",
       "0          385        610.0        511.0            914  6.111712e+06   \n",
       "1           93        675.0        543.0            221  6.806687e+06   \n",
       "2          385        610.0        511.0            914  6.111712e+06   \n",
       "3           93        675.0        543.0            221  6.806687e+06   \n",
       "4          385        610.0        511.0            914  6.111712e+06   \n",
       "\n",
       "          x_max  ...  dist_move_prev_min  dist_move_prev_sum  x_y_min_mean  \\\n",
       "0  6.146439e+06  ...                 0.0       167403.635587   3951.751016   \n",
       "1  6.965640e+06  ...                 0.0       539855.200175   3285.973541   \n",
       "2  6.146439e+06  ...                 0.0       167403.635587   3951.751016   \n",
       "3  6.965640e+06  ...                 0.0       539855.200175   3285.973541   \n",
       "4  6.146439e+06  ...                 0.0       167403.635587   3951.751016   \n",
       "\n",
       "   x_y_min_min  y_x_min_mean  y_x_min_min  x_y_max_mean   x_y_max_min  \\\n",
       "0          0.0   2010.203566          0.0  -1994.875200 -27993.134668   \n",
       "1          0.0  35750.598766          0.0  -1703.494682 -46893.002685   \n",
       "2          0.0   2010.203566          0.0  -1994.875200 -27993.134668   \n",
       "3          0.0  35750.598766          0.0  -1703.494682 -46893.002685   \n",
       "4          0.0   2010.203566          0.0  -1994.875200 -27993.134668   \n",
       "\n",
       "   y_x_max_mean    y_x_max_min  \n",
       "0  -5527.254366 -103239.952092  \n",
       "1 -32262.980249 -318563.512015  \n",
       "2  -5527.254366 -103239.952092  \n",
       "3 -32262.980249 -318563.512015  \n",
       "4  -5527.254366 -103239.952092  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(g,on='id',how='left')\n",
    "new_cols = [i for i in df.columns if i not in pre_cols]\n",
    "df[new_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:36.346583Z",
     "start_time": "2021-04-20T00:40:36.315237Z"
    }
   },
   "outputs": [],
   "source": [
    "# def group_feature(df, key, target, aggs,flag):   \n",
    "#     \"\"\"通过字典的形式来构建方法和重命名\"\"\"\n",
    "#     agg_dict = {}\n",
    "#     for ag in aggs:\n",
    "#         agg_dict['{}_{}_{}'.format(target,ag,flag)] = ag\n",
    "#     print(agg_dict)\n",
    "#     t = df.groupby(key, as_index=False)[target].agg(agg_dict).reset_index()\n",
    "#     return t\n",
    "def group_feature(df, key, target, aggs,flag):   \n",
    "    \"\"\"通过字典的形式来构建方法和重命名\"\"\"\n",
    "    agg_dict = {}\n",
    "    agg_list = []\n",
    "    for ag in aggs:\n",
    "#         agg_dict['{}_{}_{}'.format(target,ag,flag)] = ag\n",
    "        agg_list.append(['{}_{}_{}'.format(target,ag,flag), ag])\n",
    "#     print(agg_dict)\n",
    "#     t = df.groupby(key)[target].agg(agg_dict).reset_index()\n",
    "    t = df.groupby(key)[target].agg(agg_list).reset_index()\n",
    "    return t\n",
    "\n",
    "def extract_feature(df, train, flag):\n",
    "    '''\n",
    "    统计feature\n",
    "    注意理解group_feature的使用和效果\n",
    "    '''\n",
    "    if (flag == 'on_night') or (flag == 'on_day'): \n",
    "        t = group_feature(df, 'ship','speed',['max','mean','median','std','skew'],flag)\n",
    "        train = pd.merge(train, t, on='ship', how='left')\n",
    "        # return train\n",
    "    \n",
    "    \n",
    "    if flag == \"0\":\n",
    "        t = group_feature(df, 'ship','direction',['max','median','mean','std','skew'],flag)\n",
    "        train = pd.merge(train, t, on='ship', how='left')  \n",
    "    elif flag == \"1\":\n",
    "        t = group_feature(df, 'ship','speed',['max','mean','median','std','skew'],flag)\n",
    "        train = pd.merge(train, t, on='ship', how='left')\n",
    "        t = group_feature(df, 'ship','direction',['max','median','mean','std','skew'],flag)\n",
    "        train = pd.merge(train, t, on='ship', how='left') \n",
    "        # .nunique().to_dict() 将nunique得到的对应唯一值统计量做成字典\n",
    "        # to_dict() 与 map的使用可以很方便地构建一些统计量映射特征，如CTR（分类）问题中的转化率\n",
    "        # 提问： 如果根据训练集给定的label(0,1)来构建训练集+测试集的转化率特征，注：测试集与训练集存在部分id相同\n",
    "        hour_nunique = df.groupby('ship')['speed'].nunique().to_dict()\n",
    "        train['speed_nunique_{}'.format(flag)] = train['ship'].map(hour_nunique)   \n",
    "        hour_nunique = df.groupby('ship')['direction'].nunique().to_dict()\n",
    "        train['direction_nunique_{}'.format(flag)] = train['ship'].map(hour_nunique)  \n",
    "\n",
    "    t = group_feature(df, 'ship','x',['max','min','mean','median','std','skew'],flag)\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','y',['max','min','mean','median','std','skew'],flag)\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','base_dis_diff',['max','min','mean','std','skew'],flag)\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "\n",
    "       \n",
    "    train['x_max_x_min_{}'.format(flag)] = train['x_max_{}'.format(flag)] - train['x_min_{}'.format(flag)]\n",
    "    train['y_max_y_min_{}'.format(flag)] = train['y_max_{}'.format(flag)] - train['y_min_{}'.format(flag)]\n",
    "    train['y_max_x_min_{}'.format(flag)] = train['y_max_{}'.format(flag)] - train['x_min_{}'.format(flag)]\n",
    "    train['x_max_y_min_{}'.format(flag)] = train['x_max_{}'.format(flag)] - train['y_min_{}'.format(flag)]\n",
    "    train['slope_{}'.format(flag)] = train['y_max_y_min_{}'.format(flag)] / np.where(train['x_max_x_min_{}'.format(flag)]==0, 0.001, train['x_max_x_min_{}'.format(flag)])\n",
    "    train['area_{}'.format(flag)] = train['x_max_x_min_{}'.format(flag)] * train['y_max_y_min_{}'.format(flag)] \n",
    "    \n",
    "    mode_hour = df.groupby('ship')['hour'].agg(lambda x:x.value_counts().index[0]).to_dict()\n",
    "    train['mode_hour_{}'.format(flag)] = train['ship'].map(mode_hour)\n",
    "    train['slope_median_{}'.format(flag)] = train['y_median_{}'.format(flag)] / np.where(train['x_median_{}'.format(flag)]==0, 0.001, train['x_median_{}'.format(flag)])\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:38.573683Z",
     "start_time": "2021-04-20T00:40:38.094340Z"
    }
   },
   "outputs": [],
   "source": [
    "data  = df.copy()\n",
    "data.rename(columns={\n",
    "    'id':'ship',\n",
    "    'v':'speed',\n",
    "    'dir':'direction'\n",
    "},inplace=True)\n",
    "# 去重\n",
    "data_label = data.drop_duplicates(['ship'],keep = 'first')\n",
    "\n",
    "data_1 = data[data['speed']==0]\n",
    "data_2 = data[data['speed']!=0]\n",
    "data_label = extract_feature(data_1, data_label,\"0\")\n",
    "data_label = extract_feature(data_2, data_label,\"1\")\n",
    "\n",
    "data_1 = data[data['day_nig'] == 0]\n",
    "data_2 = data[data['day_nig'] == 1]\n",
    "data_label = extract_feature(data_1, data_label,\"on_night\")\n",
    "data_label = extract_feature(data_2, data_label,\"on_day\")\n",
    "data_label.rename(columns={'ship':'id','speed':'v','direction':'dir'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:42.015301Z",
     "start_time": "2021-04-20T00:40:41.894091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction_max_0</th>\n",
       "      <th>direction_median_0</th>\n",
       "      <th>direction_mean_0</th>\n",
       "      <th>direction_std_0</th>\n",
       "      <th>direction_skew_0</th>\n",
       "      <th>x_max_0</th>\n",
       "      <th>x_min_0</th>\n",
       "      <th>x_mean_0</th>\n",
       "      <th>x_median_0</th>\n",
       "      <th>x_std_0</th>\n",
       "      <th>...</th>\n",
       "      <th>base_dis_diff_std_on_day</th>\n",
       "      <th>base_dis_diff_skew_on_day</th>\n",
       "      <th>x_max_x_min_on_day</th>\n",
       "      <th>y_max_y_min_on_day</th>\n",
       "      <th>y_max_x_min_on_day</th>\n",
       "      <th>x_max_y_min_on_day</th>\n",
       "      <th>slope_on_day</th>\n",
       "      <th>area_on_day</th>\n",
       "      <th>mode_hour_on_day</th>\n",
       "      <th>slope_median_on_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.102853e+06</td>\n",
       "      <td>6.102751e+06</td>\n",
       "      <td>6.102817e+06</td>\n",
       "      <td>6.102853e+06</td>\n",
       "      <td>48.919553</td>\n",
       "      <td>...</td>\n",
       "      <td>8609.844843</td>\n",
       "      <td>0.945951</td>\n",
       "      <td>43889.138000</td>\n",
       "      <td>36438.288957</td>\n",
       "      <td>-9.899016e+05</td>\n",
       "      <td>1.070229e+06</td>\n",
       "      <td>0.830235</td>\n",
       "      <td>1.599245e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>0.837728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>85.764706</td>\n",
       "      <td>103.134942</td>\n",
       "      <td>0.817325</td>\n",
       "      <td>6.963742e+06</td>\n",
       "      <td>6.739805e+06</td>\n",
       "      <td>6.823112e+06</td>\n",
       "      <td>6.756708e+06</td>\n",
       "      <td>103589.588732</td>\n",
       "      <td>...</td>\n",
       "      <td>90377.633369</td>\n",
       "      <td>1.022255</td>\n",
       "      <td>325691.519166</td>\n",
       "      <td>149044.447600</td>\n",
       "      <td>-1.057917e+06</td>\n",
       "      <td>1.532653e+06</td>\n",
       "      <td>0.457625</td>\n",
       "      <td>4.854251e+10</td>\n",
       "      <td>18</td>\n",
       "      <td>0.812848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.102853e+06</td>\n",
       "      <td>6.102751e+06</td>\n",
       "      <td>6.102817e+06</td>\n",
       "      <td>6.102853e+06</td>\n",
       "      <td>48.919553</td>\n",
       "      <td>...</td>\n",
       "      <td>8609.844843</td>\n",
       "      <td>0.945951</td>\n",
       "      <td>43889.138000</td>\n",
       "      <td>36438.288957</td>\n",
       "      <td>-9.899016e+05</td>\n",
       "      <td>1.070229e+06</td>\n",
       "      <td>0.830235</td>\n",
       "      <td>1.599245e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>0.837728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>85.764706</td>\n",
       "      <td>103.134942</td>\n",
       "      <td>0.817325</td>\n",
       "      <td>6.963742e+06</td>\n",
       "      <td>6.739805e+06</td>\n",
       "      <td>6.823112e+06</td>\n",
       "      <td>6.756708e+06</td>\n",
       "      <td>103589.588732</td>\n",
       "      <td>...</td>\n",
       "      <td>90377.633369</td>\n",
       "      <td>1.022255</td>\n",
       "      <td>325691.519166</td>\n",
       "      <td>149044.447600</td>\n",
       "      <td>-1.057917e+06</td>\n",
       "      <td>1.532653e+06</td>\n",
       "      <td>0.457625</td>\n",
       "      <td>4.854251e+10</td>\n",
       "      <td>18</td>\n",
       "      <td>0.812848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.102853e+06</td>\n",
       "      <td>6.102751e+06</td>\n",
       "      <td>6.102817e+06</td>\n",
       "      <td>6.102853e+06</td>\n",
       "      <td>48.919553</td>\n",
       "      <td>...</td>\n",
       "      <td>8609.844843</td>\n",
       "      <td>0.945951</td>\n",
       "      <td>43889.138000</td>\n",
       "      <td>36438.288957</td>\n",
       "      <td>-9.899016e+05</td>\n",
       "      <td>1.070229e+06</td>\n",
       "      <td>0.830235</td>\n",
       "      <td>1.599245e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>0.837728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   direction_max_0  direction_median_0  direction_mean_0  direction_std_0  \\\n",
       "0              0.0                 0.0          0.000000         0.000000   \n",
       "1            301.0                40.0         85.764706       103.134942   \n",
       "2              0.0                 0.0          0.000000         0.000000   \n",
       "3            301.0                40.0         85.764706       103.134942   \n",
       "4              0.0                 0.0          0.000000         0.000000   \n",
       "\n",
       "   direction_skew_0       x_max_0       x_min_0      x_mean_0    x_median_0  \\\n",
       "0          0.000000  6.102853e+06  6.102751e+06  6.102817e+06  6.102853e+06   \n",
       "1          0.817325  6.963742e+06  6.739805e+06  6.823112e+06  6.756708e+06   \n",
       "2          0.000000  6.102853e+06  6.102751e+06  6.102817e+06  6.102853e+06   \n",
       "3          0.817325  6.963742e+06  6.739805e+06  6.823112e+06  6.756708e+06   \n",
       "4          0.000000  6.102853e+06  6.102751e+06  6.102817e+06  6.102853e+06   \n",
       "\n",
       "         x_std_0  ...  base_dis_diff_std_on_day  base_dis_diff_skew_on_day  \\\n",
       "0      48.919553  ...               8609.844843                   0.945951   \n",
       "1  103589.588732  ...              90377.633369                   1.022255   \n",
       "2      48.919553  ...               8609.844843                   0.945951   \n",
       "3  103589.588732  ...              90377.633369                   1.022255   \n",
       "4      48.919553  ...               8609.844843                   0.945951   \n",
       "\n",
       "   x_max_x_min_on_day  y_max_y_min_on_day  y_max_x_min_on_day  \\\n",
       "0        43889.138000        36438.288957       -9.899016e+05   \n",
       "1       325691.519166       149044.447600       -1.057917e+06   \n",
       "2        43889.138000        36438.288957       -9.899016e+05   \n",
       "3       325691.519166       149044.447600       -1.057917e+06   \n",
       "4        43889.138000        36438.288957       -9.899016e+05   \n",
       "\n",
       "   x_max_y_min_on_day  slope_on_day   area_on_day  mode_hour_on_day  \\\n",
       "0        1.070229e+06      0.830235  1.599245e+09                19   \n",
       "1        1.532653e+06      0.457625  4.854251e+10                18   \n",
       "2        1.070229e+06      0.830235  1.599245e+09                19   \n",
       "3        1.532653e+06      0.457625  4.854251e+10                18   \n",
       "4        1.070229e+06      0.830235  1.599245e+09                19   \n",
       "\n",
       "   slope_median_on_day  \n",
       "0             0.837728  \n",
       "1             0.812848  \n",
       "2             0.837728  \n",
       "3             0.812848  \n",
       "4             0.837728  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = [i for i in data_label.columns if i not in df.columns]\n",
    "df = df.merge(data_label[new_cols+['id']],on='id',how='left')\n",
    "\n",
    "df[new_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分组统计特征\n",
    "##### 划分数据后进行统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:45.552018Z",
     "start_time": "2021-04-20T00:40:44.943531Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "temp = df.copy()\n",
    "temp.rename(columns={'id':'ship','dir':'d'},inplace=True)\n",
    "\n",
    "def coefficient_of_variation(x):\n",
    "    x = x.values\n",
    "    if np.mean(x) == 0:\n",
    "        return 0\n",
    "    return np.std(x) / np.mean(x)\n",
    "\n",
    "def max_2(x):\n",
    "    x = list(x.values)\n",
    "    x.sort(reverse=True)\n",
    "    return x[1]\n",
    "\n",
    "def max_3(x):\n",
    "    x = list(x.values)\n",
    "    x.sort(reverse=True)\n",
    "    return x[2]\n",
    "\n",
    "def diff_abs_mean(x):  # 统计特征 deta绝对值均值\n",
    "    return np.mean(np.abs(np.diff(x)))\n",
    "\n",
    "f1 = pd.DataFrame()\n",
    "for col in ['x', 'y', 'v', 'd']:\n",
    "    features = temp.groupby('ship', as_index=False)[col].agg({\n",
    "        '{}_min'.format(col): 'min',\n",
    "        '{}_max'.format(col): 'max',\n",
    "        '{}_mean'.format(col): 'mean',\n",
    "        '{}_median'.format(col): 'median',\n",
    "        '{}_std'.format(col): 'std',\n",
    "        '{}_skew'.format(col): 'skew',\n",
    "        '{}_sum'.format(col): 'sum',\n",
    "        '{}_diff_abs_mean'.format(col): diff_abs_mean,\n",
    "        '{}_mode'.format(col): lambda x: x.value_counts().index[0],\n",
    "        '{}_coefficient_of_variation'.format(col): coefficient_of_variation,\n",
    "        '{}_max2'.format(col): max_2,\n",
    "        '{}_max3'.format(col): max_3\n",
    "    })\n",
    "    if f1.shape[0] == 0:\n",
    "        f1 = features\n",
    "    else:\n",
    "        f1 = f1.merge(features, on='ship', how='left')\n",
    "\n",
    "f1['x_max_x_min'] = f1['x_max'] - f1['x_min']\n",
    "f1['y_max_y_min'] = f1['y_max'] - f1['y_min']\n",
    "f1['y_max_x_min'] = f1['y_max'] - f1['x_min']\n",
    "f1['x_max_y_min'] = f1['x_max'] - f1['y_min']\n",
    "f1['slope'] = f1['y_max_y_min'] / np.where(f1['x_max_x_min'] == 0, 0.001, f1['x_max_x_min'])\n",
    "f1['area'] = f1['x_max_x_min'] * f1['y_max_y_min']\n",
    "f1['dis_max_min'] = (f1['x_max_x_min'] ** 2 + f1['y_max_y_min'] ** 2) ** 0.5\n",
    "f1['dis_mean'] = (f1['x_mean'] ** 2 + f1['y_mean'] ** 2) ** 0.5\n",
    "f1['area_d_dis_max_min'] = f1['area'] / f1['dis_max_min']\n",
    "\n",
    "# 加速度\n",
    "temp.sort_values(['ship', 'time'], ascending=True, inplace=True)\n",
    "temp['ynext'] = temp.groupby('ship')['y'].shift(-1)\n",
    "temp['xnext'] = temp.groupby('ship')['x'].shift(-1)\n",
    "temp['ynext'] = temp['ynext'].fillna(method='ffill')\n",
    "temp['xnext'] = temp['xnext'].fillna(method='ffill')\n",
    "temp['timenext'] = temp.groupby('ship')['time'].shift(-1)\n",
    "temp['timediff'] = np.abs(temp['timenext'] - temp['time'])\n",
    "temp['a_y'] = temp.apply(lambda x: (x['ynext'] - x['y']) / x['timediff'].total_seconds(), axis=1)\n",
    "temp['a_x'] = temp.apply(lambda x: (x['xnext'] - x['x']) / x['timediff'].total_seconds(), axis=1)\n",
    "for col in ['a_y', 'a_x']:\n",
    "    f2 = temp.groupby('ship', as_index=False)[col].agg({\n",
    "        '{}_max'.format(col): 'max',\n",
    "        '{}_mean'.format(col): 'mean',\n",
    "        '{}_min'.format(col): 'min',\n",
    "        '{}_median'.format(col): 'median',\n",
    "        '{}_std'.format(col): 'std'})\n",
    "    f1 = f1.merge(f2, on='ship', how='left')\n",
    "\n",
    "# 曲率\n",
    "temp['y_pre'] = temp.groupby('ship')['y'].shift(1)\n",
    "temp['x_pre'] = temp.groupby('ship')['x'].shift(1)\n",
    "temp['y_pre'] = temp['y_pre'].fillna(method='bfill')\n",
    "temp['x_pre'] = temp['x_pre'].fillna(method='bfill')\n",
    "temp['d_pre'] = ((temp['x'] - temp['x_pre']) ** 2 + (temp['y'] - temp['y_pre']) ** 2) ** 0.5\n",
    "temp['d_next'] = ((temp['xnext'] - temp['x']) ** 2 + (temp['ynext'] - temp['y']) ** 2) ** 0.5\n",
    "temp['d_pre_next'] = ((temp['xnext'] - temp['x_pre']) ** 2 + (temp['ynext'] - temp['y_pre']) ** 2) ** 0.5\n",
    "temp['curvature'] = (temp['d_pre'] + temp['d_next']) / temp['d_pre_next']\n",
    "\n",
    "f2 = temp.groupby('ship', as_index=False)['curvature'].agg({\n",
    "    'curvature_max': 'max',\n",
    "    'curvature_mean': 'mean',\n",
    "    'curvature_min': 'min',\n",
    "    'curvature_median': 'median',\n",
    "    'curvature_std': 'std'})\n",
    "f1 = f1.merge(f2, on='ship', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:56:30.857351Z",
     "start_time": "2021-04-19T05:56:25.169Z"
    }
   },
   "source": [
    "#### embedding特征\n",
    "#####  Word2vec构造词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:49.007056Z",
     "start_time": "2021-04-20T00:40:48.994551Z"
    }
   },
   "outputs": [],
   "source": [
    "def traj_cbow_embedding(traj_data_corpus=None, embedding_size=70,\n",
    "                        iters=40, min_count=3, window_size=25,\n",
    "                        seed=9012, num_runs=5, word_feat=\"no_bin\"):\n",
    "    \"\"\"CBOW embedding for trajectory data.\"\"\"\n",
    "    boat_id = traj_data_corpus['id'].unique()\n",
    "    sentences, embedding_df_list, embedding_model_list = [], [], []\n",
    "    for i in boat_id:\n",
    "        traj = traj_data_corpus[traj_data_corpus['id']==i]\n",
    "        sentences.append(traj[word_feat].values.tolist())\n",
    "\n",
    "    print(\"\\n@Start CBOW word embedding at {}\".format(datetime.now()))\n",
    "    print(\"-------------------------------------------\")\n",
    "    for i in tqdm(range(num_runs)):\n",
    "        model = Word2Vec(sentences, size=embedding_size,\n",
    "                                  min_count=min_count,\n",
    "                                  workers=mp.cpu_count(),\n",
    "                                  window=window_size,\n",
    "                                  seed=seed, iter=iters, sg=0)\n",
    "\n",
    "        # Sentance vector\n",
    "        embedding_vec = []\n",
    "        for ind, seq in enumerate(sentences):\n",
    "            seq_vec, word_count = 0, 0\n",
    "            for word in seq:\n",
    "                if word not in model:\n",
    "                    continue\n",
    "                else:\n",
    "                    seq_vec += model[word]\n",
    "                    word_count += 1\n",
    "            if word_count == 0:\n",
    "                embedding_vec.append(embedding_size * [0])\n",
    "            else:\n",
    "                embedding_vec.append(seq_vec / word_count)\n",
    "        embedding_vec = np.array(embedding_vec)\n",
    "        embedding_cbow_df = pd.DataFrame(embedding_vec, \n",
    "            columns=[\"embedding_cbow_{}_{}\".format(word_feat, i) for i in range(embedding_size)])\n",
    "        embedding_cbow_df[\"id\"] = boat_id\n",
    "        embedding_df_list.append(embedding_cbow_df)\n",
    "        embedding_model_list.append(model)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"@End CBOW word embedding at {}\".format(datetime.now()))\n",
    "    return embedding_df_list, embedding_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:40:53.209952Z",
     "start_time": "2021-04-20T00:40:52.579916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@Start CBOW word embedding at 2021-04-20 08:40:52.612425\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "@End CBOW word embedding at 2021-04-20 08:40:53.179347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_size=70\n",
    "iters=70\n",
    "min_count=3\n",
    "window_size=25\n",
    "num_runs=1\n",
    "\n",
    "df_list, model_list = traj_cbow_embedding(df,\n",
    "                                          embedding_size=embedding_size,\n",
    "                                          iters=iters, min_count=min_count,\n",
    "                                          window_size=window_size,\n",
    "                                          seed=9012,\n",
    "                                          num_runs=num_runs,\n",
    "                                          word_feat=\"no_bin\")\n",
    "\n",
    "train_embedding_df_list = [d.reset_index(drop=True) for d in df_list]\n",
    "fea = train_embedding_df_list[0]\n",
    "fea = pd.DataFrame(fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:41:00.144019Z",
     "start_time": "2021-04-20T00:40:59.916047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_cbow_no_bin_0</th>\n",
       "      <th>embedding_cbow_no_bin_1</th>\n",
       "      <th>embedding_cbow_no_bin_2</th>\n",
       "      <th>embedding_cbow_no_bin_3</th>\n",
       "      <th>embedding_cbow_no_bin_4</th>\n",
       "      <th>embedding_cbow_no_bin_5</th>\n",
       "      <th>embedding_cbow_no_bin_6</th>\n",
       "      <th>embedding_cbow_no_bin_7</th>\n",
       "      <th>embedding_cbow_no_bin_8</th>\n",
       "      <th>embedding_cbow_no_bin_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_cbow_no_bin_60</th>\n",
       "      <th>embedding_cbow_no_bin_61</th>\n",
       "      <th>embedding_cbow_no_bin_62</th>\n",
       "      <th>embedding_cbow_no_bin_63</th>\n",
       "      <th>embedding_cbow_no_bin_64</th>\n",
       "      <th>embedding_cbow_no_bin_65</th>\n",
       "      <th>embedding_cbow_no_bin_66</th>\n",
       "      <th>embedding_cbow_no_bin_67</th>\n",
       "      <th>embedding_cbow_no_bin_68</th>\n",
       "      <th>embedding_cbow_no_bin_69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.296518</td>\n",
       "      <td>-1.381415</td>\n",
       "      <td>-1.751447</td>\n",
       "      <td>-2.614199</td>\n",
       "      <td>-1.398765</td>\n",
       "      <td>1.045716</td>\n",
       "      <td>1.585713</td>\n",
       "      <td>0.765186</td>\n",
       "      <td>-0.252884</td>\n",
       "      <td>1.851986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825406</td>\n",
       "      <td>-0.207794</td>\n",
       "      <td>-0.659545</td>\n",
       "      <td>1.122984</td>\n",
       "      <td>-0.139747</td>\n",
       "      <td>1.99854</td>\n",
       "      <td>-1.693542</td>\n",
       "      <td>0.77139</td>\n",
       "      <td>1.579915</td>\n",
       "      <td>0.400014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.296518</td>\n",
       "      <td>-1.381416</td>\n",
       "      <td>-1.751446</td>\n",
       "      <td>-2.614197</td>\n",
       "      <td>-1.398766</td>\n",
       "      <td>1.045716</td>\n",
       "      <td>1.585714</td>\n",
       "      <td>0.765185</td>\n",
       "      <td>-0.252885</td>\n",
       "      <td>1.851985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825406</td>\n",
       "      <td>-0.207794</td>\n",
       "      <td>-0.659545</td>\n",
       "      <td>1.122984</td>\n",
       "      <td>-0.139747</td>\n",
       "      <td>1.99854</td>\n",
       "      <td>-1.693542</td>\n",
       "      <td>0.77139</td>\n",
       "      <td>1.579916</td>\n",
       "      <td>0.400014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.296518</td>\n",
       "      <td>-1.381415</td>\n",
       "      <td>-1.751447</td>\n",
       "      <td>-2.614199</td>\n",
       "      <td>-1.398765</td>\n",
       "      <td>1.045716</td>\n",
       "      <td>1.585713</td>\n",
       "      <td>0.765186</td>\n",
       "      <td>-0.252884</td>\n",
       "      <td>1.851986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825406</td>\n",
       "      <td>-0.207794</td>\n",
       "      <td>-0.659545</td>\n",
       "      <td>1.122984</td>\n",
       "      <td>-0.139747</td>\n",
       "      <td>1.99854</td>\n",
       "      <td>-1.693542</td>\n",
       "      <td>0.77139</td>\n",
       "      <td>1.579915</td>\n",
       "      <td>0.400014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.296518</td>\n",
       "      <td>-1.381416</td>\n",
       "      <td>-1.751446</td>\n",
       "      <td>-2.614197</td>\n",
       "      <td>-1.398766</td>\n",
       "      <td>1.045716</td>\n",
       "      <td>1.585714</td>\n",
       "      <td>0.765185</td>\n",
       "      <td>-0.252885</td>\n",
       "      <td>1.851985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825406</td>\n",
       "      <td>-0.207794</td>\n",
       "      <td>-0.659545</td>\n",
       "      <td>1.122984</td>\n",
       "      <td>-0.139747</td>\n",
       "      <td>1.99854</td>\n",
       "      <td>-1.693542</td>\n",
       "      <td>0.77139</td>\n",
       "      <td>1.579916</td>\n",
       "      <td>0.400014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.296518</td>\n",
       "      <td>-1.381415</td>\n",
       "      <td>-1.751447</td>\n",
       "      <td>-2.614199</td>\n",
       "      <td>-1.398765</td>\n",
       "      <td>1.045716</td>\n",
       "      <td>1.585713</td>\n",
       "      <td>0.765186</td>\n",
       "      <td>-0.252884</td>\n",
       "      <td>1.851986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825406</td>\n",
       "      <td>-0.207794</td>\n",
       "      <td>-0.659545</td>\n",
       "      <td>1.122984</td>\n",
       "      <td>-0.139747</td>\n",
       "      <td>1.99854</td>\n",
       "      <td>-1.693542</td>\n",
       "      <td>0.77139</td>\n",
       "      <td>1.579915</td>\n",
       "      <td>0.400014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_cbow_no_bin_0  embedding_cbow_no_bin_1  embedding_cbow_no_bin_2  \\\n",
       "0                -0.296518                -1.381415                -1.751447   \n",
       "1                -0.296518                -1.381416                -1.751446   \n",
       "2                -0.296518                -1.381415                -1.751447   \n",
       "3                -0.296518                -1.381416                -1.751446   \n",
       "4                -0.296518                -1.381415                -1.751447   \n",
       "\n",
       "   embedding_cbow_no_bin_3  embedding_cbow_no_bin_4  embedding_cbow_no_bin_5  \\\n",
       "0                -2.614199                -1.398765                 1.045716   \n",
       "1                -2.614197                -1.398766                 1.045716   \n",
       "2                -2.614199                -1.398765                 1.045716   \n",
       "3                -2.614197                -1.398766                 1.045716   \n",
       "4                -2.614199                -1.398765                 1.045716   \n",
       "\n",
       "   embedding_cbow_no_bin_6  embedding_cbow_no_bin_7  embedding_cbow_no_bin_8  \\\n",
       "0                 1.585713                 0.765186                -0.252884   \n",
       "1                 1.585714                 0.765185                -0.252885   \n",
       "2                 1.585713                 0.765186                -0.252884   \n",
       "3                 1.585714                 0.765185                -0.252885   \n",
       "4                 1.585713                 0.765186                -0.252884   \n",
       "\n",
       "   embedding_cbow_no_bin_9  ...  embedding_cbow_no_bin_60  \\\n",
       "0                 1.851986  ...                 -0.825406   \n",
       "1                 1.851985  ...                 -0.825406   \n",
       "2                 1.851986  ...                 -0.825406   \n",
       "3                 1.851985  ...                 -0.825406   \n",
       "4                 1.851986  ...                 -0.825406   \n",
       "\n",
       "   embedding_cbow_no_bin_61  embedding_cbow_no_bin_62  \\\n",
       "0                 -0.207794                 -0.659545   \n",
       "1                 -0.207794                 -0.659545   \n",
       "2                 -0.207794                 -0.659545   \n",
       "3                 -0.207794                 -0.659545   \n",
       "4                 -0.207794                 -0.659545   \n",
       "\n",
       "   embedding_cbow_no_bin_63  embedding_cbow_no_bin_64  \\\n",
       "0                  1.122984                 -0.139747   \n",
       "1                  1.122984                 -0.139747   \n",
       "2                  1.122984                 -0.139747   \n",
       "3                  1.122984                 -0.139747   \n",
       "4                  1.122984                 -0.139747   \n",
       "\n",
       "   embedding_cbow_no_bin_65  embedding_cbow_no_bin_66  \\\n",
       "0                   1.99854                 -1.693542   \n",
       "1                   1.99854                 -1.693542   \n",
       "2                   1.99854                 -1.693542   \n",
       "3                   1.99854                 -1.693542   \n",
       "4                   1.99854                 -1.693542   \n",
       "\n",
       "   embedding_cbow_no_bin_67  embedding_cbow_no_bin_68  \\\n",
       "0                   0.77139                  1.579915   \n",
       "1                   0.77139                  1.579916   \n",
       "2                   0.77139                  1.579915   \n",
       "3                   0.77139                  1.579916   \n",
       "4                   0.77139                  1.579915   \n",
       "\n",
       "   embedding_cbow_no_bin_69  \n",
       "0                  0.400014  \n",
       "1                  0.400014  \n",
       "2                  0.400014  \n",
       "3                  0.400014  \n",
       "4                  0.400014  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_cols = df.columns\n",
    "df = df.merge(fea,on='id',how='left')\n",
    "\n",
    "\n",
    "new_cols = [i for i in df.columns if i not in pre_cols]\n",
    "df[new_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:41:07.100396Z",
     "start_time": "2021-04-20T00:41:06.245221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@Round 2 speed embedding:\n",
      "\n",
      "@Start CBOW word embedding at 2021-04-20 08:41:06.286387\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "@End CBOW word embedding at 2021-04-20 08:41:06.619359\n",
      "\n",
      "@Round 2 direction embedding:\n",
      "\n",
      "@Start CBOW word embedding at 2021-04-20 08:41:06.646096\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "@End CBOW word embedding at 2021-04-20 08:41:07.084008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "boat_id = df['id'].unique()\n",
    "total_embedding = pd.DataFrame(boat_id, columns=[\"id\"])\n",
    "traj_data = df[['v','dir','id']].rename(columns = {'v':'speed','dir':'direction'})\n",
    "\n",
    "# Step 1: Construct the words\n",
    "traj_data_corpus = []\n",
    "traj_data[\"speed_str\"]     = traj_data[\"speed\"].apply(lambda x: str(int(x*100)))\n",
    "traj_data[\"direction_str\"] = traj_data[\"direction\"].apply(str)\n",
    "traj_data[\"speed_dir_str\"] = traj_data[\"speed_str\"] + \"_\" + traj_data[\"direction_str\"]\n",
    "traj_data_corpus = traj_data[[\"id\", \"speed_str\",\n",
    "                                  \"direction_str\", \"speed_dir_str\"]]\n",
    "print(\"\\n@Round 2 speed embedding:\")\n",
    "df_list, model_list = traj_cbow_embedding(traj_data_corpus,\n",
    "                                          embedding_size=10,\n",
    "                                          iters=40, min_count=3,\n",
    "                                          window_size=25, seed=9102,\n",
    "                                          num_runs=1, word_feat=\"speed_str\")\n",
    "speed_embedding = df_list[0].reset_index(drop=True)\n",
    "total_embedding = pd.merge(total_embedding, speed_embedding,\n",
    "                           on=\"id\", how=\"left\")\n",
    "\n",
    "\n",
    "print(\"\\n@Round 2 direction embedding:\")\n",
    "df_list, model_list = traj_cbow_embedding(traj_data_corpus,\n",
    "                                          embedding_size=12,\n",
    "                                          iters=70, min_count=3,\n",
    "                                          window_size=25, seed=9102,\n",
    "                                          num_runs=1, word_feat=\"speed_dir_str\")\n",
    "speed_dir_embedding = df_list[0].reset_index(drop=True)\n",
    "total_embedding = pd.merge(total_embedding, speed_dir_embedding,\n",
    "                           on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:41:13.613193Z",
     "start_time": "2021-04-20T00:41:13.481035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_cbow_speed_str_0</th>\n",
       "      <th>embedding_cbow_speed_str_1</th>\n",
       "      <th>embedding_cbow_speed_str_2</th>\n",
       "      <th>embedding_cbow_speed_str_3</th>\n",
       "      <th>embedding_cbow_speed_str_4</th>\n",
       "      <th>embedding_cbow_speed_str_5</th>\n",
       "      <th>embedding_cbow_speed_str_6</th>\n",
       "      <th>embedding_cbow_speed_str_7</th>\n",
       "      <th>embedding_cbow_speed_str_8</th>\n",
       "      <th>embedding_cbow_speed_str_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_cbow_speed_dir_str_2</th>\n",
       "      <th>embedding_cbow_speed_dir_str_3</th>\n",
       "      <th>embedding_cbow_speed_dir_str_4</th>\n",
       "      <th>embedding_cbow_speed_dir_str_5</th>\n",
       "      <th>embedding_cbow_speed_dir_str_6</th>\n",
       "      <th>embedding_cbow_speed_dir_str_7</th>\n",
       "      <th>embedding_cbow_speed_dir_str_8</th>\n",
       "      <th>embedding_cbow_speed_dir_str_9</th>\n",
       "      <th>embedding_cbow_speed_dir_str_10</th>\n",
       "      <th>embedding_cbow_speed_dir_str_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.918525</td>\n",
       "      <td>-0.505222</td>\n",
       "      <td>-2.032478</td>\n",
       "      <td>0.745203</td>\n",
       "      <td>1.776894</td>\n",
       "      <td>3.214431</td>\n",
       "      <td>1.974173</td>\n",
       "      <td>-4.381144</td>\n",
       "      <td>-3.217552</td>\n",
       "      <td>-2.600746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343606</td>\n",
       "      <td>3.504519</td>\n",
       "      <td>-0.923818</td>\n",
       "      <td>2.080787</td>\n",
       "      <td>2.996411</td>\n",
       "      <td>-1.263102</td>\n",
       "      <td>1.427308</td>\n",
       "      <td>-3.428284</td>\n",
       "      <td>-2.485857</td>\n",
       "      <td>1.193597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.410860</td>\n",
       "      <td>2.054793</td>\n",
       "      <td>-1.519732</td>\n",
       "      <td>-2.662427</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>0.974712</td>\n",
       "      <td>0.801571</td>\n",
       "      <td>0.363235</td>\n",
       "      <td>-1.279728</td>\n",
       "      <td>0.106097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737868</td>\n",
       "      <td>-0.164093</td>\n",
       "      <td>-1.127899</td>\n",
       "      <td>-1.022281</td>\n",
       "      <td>0.105744</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>-0.400303</td>\n",
       "      <td>-2.012783</td>\n",
       "      <td>-0.368905</td>\n",
       "      <td>-0.106053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.918525</td>\n",
       "      <td>-0.505222</td>\n",
       "      <td>-2.032478</td>\n",
       "      <td>0.745203</td>\n",
       "      <td>1.776894</td>\n",
       "      <td>3.214431</td>\n",
       "      <td>1.974173</td>\n",
       "      <td>-4.381144</td>\n",
       "      <td>-3.217552</td>\n",
       "      <td>-2.600746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343606</td>\n",
       "      <td>3.504519</td>\n",
       "      <td>-0.923818</td>\n",
       "      <td>2.080787</td>\n",
       "      <td>2.996411</td>\n",
       "      <td>-1.263102</td>\n",
       "      <td>1.427308</td>\n",
       "      <td>-3.428284</td>\n",
       "      <td>-2.485857</td>\n",
       "      <td>1.193597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.410860</td>\n",
       "      <td>2.054793</td>\n",
       "      <td>-1.519732</td>\n",
       "      <td>-2.662427</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>0.974712</td>\n",
       "      <td>0.801571</td>\n",
       "      <td>0.363235</td>\n",
       "      <td>-1.279728</td>\n",
       "      <td>0.106097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737868</td>\n",
       "      <td>-0.164093</td>\n",
       "      <td>-1.127899</td>\n",
       "      <td>-1.022281</td>\n",
       "      <td>0.105744</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>-0.400303</td>\n",
       "      <td>-2.012783</td>\n",
       "      <td>-0.368905</td>\n",
       "      <td>-0.106053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.918525</td>\n",
       "      <td>-0.505222</td>\n",
       "      <td>-2.032478</td>\n",
       "      <td>0.745203</td>\n",
       "      <td>1.776894</td>\n",
       "      <td>3.214431</td>\n",
       "      <td>1.974173</td>\n",
       "      <td>-4.381144</td>\n",
       "      <td>-3.217552</td>\n",
       "      <td>-2.600746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343606</td>\n",
       "      <td>3.504519</td>\n",
       "      <td>-0.923818</td>\n",
       "      <td>2.080787</td>\n",
       "      <td>2.996411</td>\n",
       "      <td>-1.263102</td>\n",
       "      <td>1.427308</td>\n",
       "      <td>-3.428284</td>\n",
       "      <td>-2.485857</td>\n",
       "      <td>1.193597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_cbow_speed_str_0  embedding_cbow_speed_str_1  \\\n",
       "0                    0.918525                   -0.505222   \n",
       "1                    0.410860                    2.054793   \n",
       "2                    0.918525                   -0.505222   \n",
       "3                    0.410860                    2.054793   \n",
       "4                    0.918525                   -0.505222   \n",
       "\n",
       "   embedding_cbow_speed_str_2  embedding_cbow_speed_str_3  \\\n",
       "0                   -2.032478                    0.745203   \n",
       "1                   -1.519732                   -2.662427   \n",
       "2                   -2.032478                    0.745203   \n",
       "3                   -1.519732                   -2.662427   \n",
       "4                   -2.032478                    0.745203   \n",
       "\n",
       "   embedding_cbow_speed_str_4  embedding_cbow_speed_str_5  \\\n",
       "0                    1.776894                    3.214431   \n",
       "1                    0.996046                    0.974712   \n",
       "2                    1.776894                    3.214431   \n",
       "3                    0.996046                    0.974712   \n",
       "4                    1.776894                    3.214431   \n",
       "\n",
       "   embedding_cbow_speed_str_6  embedding_cbow_speed_str_7  \\\n",
       "0                    1.974173                   -4.381144   \n",
       "1                    0.801571                    0.363235   \n",
       "2                    1.974173                   -4.381144   \n",
       "3                    0.801571                    0.363235   \n",
       "4                    1.974173                   -4.381144   \n",
       "\n",
       "   embedding_cbow_speed_str_8  embedding_cbow_speed_str_9  ...  \\\n",
       "0                   -3.217552                   -2.600746  ...   \n",
       "1                   -1.279728                    0.106097  ...   \n",
       "2                   -3.217552                   -2.600746  ...   \n",
       "3                   -1.279728                    0.106097  ...   \n",
       "4                   -3.217552                   -2.600746  ...   \n",
       "\n",
       "   embedding_cbow_speed_dir_str_2  embedding_cbow_speed_dir_str_3  \\\n",
       "0                       -0.343606                        3.504519   \n",
       "1                       -0.737868                       -0.164093   \n",
       "2                       -0.343606                        3.504519   \n",
       "3                       -0.737868                       -0.164093   \n",
       "4                       -0.343606                        3.504519   \n",
       "\n",
       "   embedding_cbow_speed_dir_str_4  embedding_cbow_speed_dir_str_5  \\\n",
       "0                       -0.923818                        2.080787   \n",
       "1                       -1.127899                       -1.022281   \n",
       "2                       -0.923818                        2.080787   \n",
       "3                       -1.127899                       -1.022281   \n",
       "4                       -0.923818                        2.080787   \n",
       "\n",
       "   embedding_cbow_speed_dir_str_6  embedding_cbow_speed_dir_str_7  \\\n",
       "0                        2.996411                       -1.263102   \n",
       "1                        0.105744                        0.084507   \n",
       "2                        2.996411                       -1.263102   \n",
       "3                        0.105744                        0.084507   \n",
       "4                        2.996411                       -1.263102   \n",
       "\n",
       "   embedding_cbow_speed_dir_str_8  embedding_cbow_speed_dir_str_9  \\\n",
       "0                        1.427308                       -3.428284   \n",
       "1                       -0.400303                       -2.012783   \n",
       "2                        1.427308                       -3.428284   \n",
       "3                       -0.400303                       -2.012783   \n",
       "4                        1.427308                       -3.428284   \n",
       "\n",
       "   embedding_cbow_speed_dir_str_10  embedding_cbow_speed_dir_str_11  \n",
       "0                        -2.485857                         1.193597  \n",
       "1                        -0.368905                        -0.106053  \n",
       "2                        -2.485857                         1.193597  \n",
       "3                        -0.368905                        -0.106053  \n",
       "4                        -2.485857                         1.193597  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_cols = df.columns\n",
    "df = df.merge(total_embedding,on='id',how='left')\n",
    "\n",
    "new_cols = [i for i in df.columns if i not in pre_cols]\n",
    "df[new_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:56:30.875832Z",
     "start_time": "2021-04-19T05:56:25.191Z"
    }
   },
   "source": [
    "#####  NMF提取文本的主题分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:41:17.513857Z",
     "start_time": "2021-04-20T00:41:17.479367Z"
    }
   },
   "outputs": [],
   "source": [
    "class nmf_list(object):\n",
    "    def __init__(self,data,by_name,to_list,nmf_n,top_n):\n",
    "        self.data = data\n",
    "        self.by_name = by_name\n",
    "        self.to_list = to_list\n",
    "        self.nmf_n = nmf_n\n",
    "        self.top_n = top_n\n",
    "\n",
    "    def run(self,tf_n):\n",
    "        df_all = self.data.groupby(self.by_name)[self.to_list].apply(lambda x :'|'.join(x)).reset_index()\n",
    "        self.data =df_all.copy()\n",
    "\n",
    "        print('bulid word_fre')\n",
    "        # 词频的构建\n",
    "        def word_fre(x):\n",
    "            word_dict = []\n",
    "            x = x.split('|')\n",
    "            docs = []\n",
    "            for doc in x:\n",
    "                doc = doc.split()\n",
    "                docs.append(doc)\n",
    "                word_dict.extend(doc)\n",
    "            word_dict = Counter(word_dict)\n",
    "            new_word_dict = {}\n",
    "            for key,value in word_dict.items():\n",
    "                new_word_dict[key] = [value,0]\n",
    "            del word_dict  \n",
    "            del x\n",
    "            for doc in docs:\n",
    "                doc = Counter(doc)\n",
    "                for word in doc.keys():\n",
    "                    new_word_dict[word][1] += 1\n",
    "            return new_word_dict \n",
    "        self.data['word_fre'] = self.data[self.to_list].apply(word_fre)\n",
    "\n",
    "        print('bulid top_' + str(self.top_n))\n",
    "        # 设定100个高频词\n",
    "        def top_100(word_dict):\n",
    "            return sorted(word_dict.items(),key = lambda x:(x[1][1],x[1][0]),reverse = True)[:self.top_n]\n",
    "        self.data['top_'+str(self.top_n)] = self.data['word_fre'].apply(top_100)\n",
    "        def top_100_word(word_list):\n",
    "            words = []\n",
    "            for i in word_list:\n",
    "                i = list(i)\n",
    "                words.append(i[0])\n",
    "            return words \n",
    "        self.data['top_'+str(self.top_n)+'_word'] = self.data['top_' + str(self.top_n)].apply(top_100_word)\n",
    "        # print('top_'+str(self.top_n)+'_word的shape')\n",
    "        print(self.data.shape)\n",
    "\n",
    "        word_list = []\n",
    "        for i in self.data['top_'+str(self.top_n)+'_word'].values:\n",
    "            word_list.extend(i)\n",
    "        word_list = Counter(word_list)\n",
    "        word_list = sorted(word_list.items(),key = lambda x:x[1],reverse = True)\n",
    "        user_fre = []\n",
    "        for i in word_list:\n",
    "            i = list(i)\n",
    "            user_fre.append(i[1]/self.data[self.by_name].nunique())\n",
    "        stop_words = []\n",
    "        for i,j in zip(word_list,user_fre):\n",
    "            if j>0.5:\n",
    "                i = list(i)\n",
    "                stop_words.append(i[0])\n",
    "\n",
    "        print('start title_feature')\n",
    "        # 讲融合后的taglist当作一句话进行文本处理\n",
    "        self.data['title_feature'] = self.data[self.to_list].apply(lambda x: x.split('|'))\n",
    "        self.data['title_feature'] = self.data['title_feature'].apply(lambda line: [w for w in line if w not in stop_words])\n",
    "        self.data['title_feature'] = self.data['title_feature'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "        print('start NMF')\n",
    "        # 使用tfidf对元素进行处理\n",
    "        tfidf_vectorizer = TfidfVectorizer(ngram_range=(tf_n,tf_n))\n",
    "        tfidf = tfidf_vectorizer.fit_transform(self.data['title_feature'].values)\n",
    "        #使用nmf算法，提取文本的主题分布\n",
    "        text_nmf = NMF(n_components=self.nmf_n).fit_transform(tfidf)\n",
    "\n",
    "\n",
    "        # 整理并输出文件\n",
    "        name = [str(tf_n) + self.to_list + '_' +str(x) for x in range(1,self.nmf_n+1)]\n",
    "        tag_list = pd.DataFrame(text_nmf)\n",
    "        print(tag_list.shape)\n",
    "        tag_list.columns = name\n",
    "        tag_list[self.by_name] = self.data[self.by_name]\n",
    "        column_name = [self.by_name] + name\n",
    "        tag_list = tag_list[column_name]\n",
    "        return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T00:41:22.907103Z",
     "start_time": "2021-04-20T00:41:21.528449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* 1 *******\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n",
      "********* 2 *******\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n",
      "********* 3 *******\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n",
      "bulid word_fre\n",
      "bulid top_2\n",
      "(8, 5)\n",
      "start title_feature\n",
      "start NMF\n",
      "(8, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1speed_str_1</th>\n",
       "      <th>1speed_str_2</th>\n",
       "      <th>1speed_str_3</th>\n",
       "      <th>1speed_str_4</th>\n",
       "      <th>1speed_str_5</th>\n",
       "      <th>1speed_str_6</th>\n",
       "      <th>1speed_str_7</th>\n",
       "      <th>1speed_str_8</th>\n",
       "      <th>1x_str_1</th>\n",
       "      <th>1x_str_2</th>\n",
       "      <th>...</th>\n",
       "      <th>3x_str_7</th>\n",
       "      <th>3x_str_8</th>\n",
       "      <th>3y_str_1</th>\n",
       "      <th>3y_str_2</th>\n",
       "      <th>3y_str_3</th>\n",
       "      <th>3y_str_4</th>\n",
       "      <th>3y_str_5</th>\n",
       "      <th>3y_str_6</th>\n",
       "      <th>3y_str_7</th>\n",
       "      <th>3y_str_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.429569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058269</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.761026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.429569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058269</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.761026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1speed_str_1  1speed_str_2  1speed_str_3  1speed_str_4  1speed_str_5  \\\n",
       "0      0.000000      0.190613           0.0      0.000000      0.843149   \n",
       "1      0.429569      0.000000           0.0      0.058269      0.000009   \n",
       "2      0.000000      0.190613           0.0      0.000000      0.843149   \n",
       "3      0.429569      0.000000           0.0      0.058269      0.000009   \n",
       "4      0.000000      0.190613           0.0      0.000000      0.843149   \n",
       "\n",
       "   1speed_str_6  1speed_str_7  1speed_str_8  1x_str_1  1x_str_2  ...  \\\n",
       "0      0.000000           0.0      0.000022       0.0       0.0  ...   \n",
       "1      0.761026           0.0      0.000000       0.0       0.0  ...   \n",
       "2      0.000000           0.0      0.000022       0.0       0.0  ...   \n",
       "3      0.761026           0.0      0.000000       0.0       0.0  ...   \n",
       "4      0.000000           0.0      0.000022       0.0       0.0  ...   \n",
       "\n",
       "   3x_str_7  3x_str_8  3y_str_1  3y_str_2  3y_str_3  3y_str_4  3y_str_5  \\\n",
       "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1       0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3       0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "4       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   3y_str_6  3y_str_7  3y_str_8  \n",
       "0       0.0       0.0  0.952014  \n",
       "1       0.0       0.0  0.000000  \n",
       "2       0.0       0.0  0.952014  \n",
       "3       0.0       0.0  0.000000  \n",
       "4       0.0       0.0  0.952014  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data.rename(columns={'v':'speed','id':'ship'},inplace=True)\n",
    "for j in range(1,4):\n",
    "    print('********* {} *******'.format(j))\n",
    "    for i in ['speed','x','y']:\n",
    "        data[i + '_str'] = data[i].astype(str)\n",
    "        nmf = nmf_list(data,'ship',i + '_str',8,2)\n",
    "        nmf_a = nmf.run(j)\n",
    "        nmf_a.rename(columns={'ship':'id'},inplace=True)\n",
    "        data_label = data_label.merge(nmf_a,on = 'id',how = 'left')\n",
    "        \n",
    "new_cols = [i for i in data_label.columns if i not in df.columns]\n",
    "df = df.merge(data_label[new_cols+['id']],on='id',how='left')\n",
    "df[new_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按类别特征编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 均值编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T05:21:40.812107Z",
     "start_time": "2021-04-20T05:21:40.779370Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class MeanEncoder:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    def __init__(self, categorical_features, n_splits=5, target_type='classification', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    "\n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    "\n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    "\n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    "\n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    "\n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    "\n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    "\n",
    "#         col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg({'mean': 'mean', 'beta': 'size'})\n",
    "        col_avg_y = X_train.groupby(variable)['pred_temp'].agg(['mean','size']).rename(columns={'mean':'mean','size':'beta'})\n",
    "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n",
    "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n",
    "\n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    "\n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        print(self.target_type)\n",
    "        if self.target_type == 'classification':\n",
    "            \n",
    "            skf = StratifiedKFold(self.n_splits, shuffle=True,random_state=6666)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(X_new, list(y)):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target,\n",
    "                        self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(X_new, list(y)):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None,\n",
    "                        self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 减少内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T05:21:46.638878Z",
     "start_time": "2021-04-20T05:21:46.621249Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    print('Reduce mem usage....')\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('     Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T05:21:54.200966Z",
     "start_time": "2021-04-20T05:21:53.963767Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()\n",
    "# df = reduce_mem_usage(df, verbose=True)\n",
    "# fea_columns_df = pd.DataFrame(df.dtypes).reset_index()\n",
    "# fea_columns_df.columns = ['columns_','type_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:28:50.970439Z",
     "start_time": "2021-04-20T08:28:41.787506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_list = ['v_bin', 'x_bin1', 'y_bin1', 'x_end', 'y_end','id', 'x_grid', 'y_grid', 'no_bin', 'dist_move_prev_bin_sen', 'v_bin_sen']\n",
    "for i in class_list:\n",
    "    df[i] = df[i].astype(str)\n",
    "df['label'] = df['label'].astype(int)\n",
    "MeanEnocodeFeature = class_list\n",
    "ME = MeanEncoder(MeanEnocodeFeature, target_type='classification')\n",
    "dfaa = ME.fit_transform(df, df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold mean-target 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:45:25.525031Z",
     "start_time": "2021-04-20T08:45:25.500900Z"
    }
   },
   "outputs": [],
   "source": [
    "from category_encoders.target_encoder import TargetEncoder \n",
    "from sklearn import base\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.DataFrame({'Feature':['A','B','B','B','B', 'A','B','A','A','B','A','A','B','A','A','B','B','B','A','A'],\\\n",
    "                   'Target':[1,0,0,1,1, 1,0,0,0,0,1, 0,1, 0,1,0,0,0,1,1]})\n",
    "\n",
    "class KFoldTargetEncoderTrain(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def __init__(self, colnames,targetName,n_fold=5,verbosity=True,discardOriginal_col=False):\n",
    "\n",
    "        self.colnames   = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold     = n_fold\n",
    "        self.verbosity  = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)\n",
    "\n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold, shuffle = True, random_state=2019)\n",
    "\n",
    "\n",
    "\n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n",
    "        X[col_mean_name] = np.nan\n",
    "\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind] \n",
    "            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "\n",
    "        X[col_mean_name].fillna(mean_of_target, inplace = True)\n",
    "\n",
    "        if self.verbosity:\n",
    "\n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,\n",
    "                                                                                      self.targetName,\n",
    "                                                                                      np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "            \n",
    "\n",
    "        return X\n",
    "    \n",
    "class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "        \n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "\n",
    "        mean = self.train[[self.colNames,self.encodedName]].groupby(self.colNames).mean().reset_index() \n",
    "        \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "\n",
    "        \n",
    "        X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:45:33.906565Z",
     "start_time": "2021-04-20T08:45:33.790703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, Feature_Kfold_Target_Enc and, Target is 0.18053954978064135.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Target</th>\n",
       "      <th>Feature_Kfold_Target_Enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Target  Feature_Kfold_Target_Enc\n",
       "0        A       1                  0.571429\n",
       "1        B       0                  0.375000\n",
       "2        B       0                  0.333333\n",
       "3        B       1                  0.250000\n",
       "4        B       1                  0.333333\n",
       "5        A       1                  0.571429\n",
       "6        B       0                  0.333333\n",
       "7        A       0                  0.625000\n",
       "8        A       0                  0.571429\n",
       "9        B       0                  0.375000\n",
       "10       A       1                  0.571429\n",
       "11       A       0                  0.625000\n",
       "12       B       1                  0.222222\n",
       "13       A       0                  0.571429\n",
       "14       A       1                  0.625000\n",
       "15       B       0                  0.333333\n",
       "16       B       0                  0.333333\n",
       "17       B       0                  0.250000\n",
       "18       A       1                  0.571429\n",
       "19       A       1                  0.625000"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetc   = KFoldTargetEncoderTrain('Feature','Target',n_fold=5)\n",
    "new_train = targetc.fit_transform(df)\n",
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:54:33.431991Z",
     "start_time": "2021-04-20T08:54:33.413853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600.0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20000*0.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WOE编码1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T05:28:00.963280Z",
     "start_time": "2021-04-20T05:28:00.941143Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[~(df['label'] ==0),'label_0'] = 0 \n",
    "df.loc[(df['label'] ==0),'label_0'] = 1 \n",
    "df.loc[~(df['label'] ==1),'label_1'] = 0 \n",
    "df.loc[(df['label'] ==1),'label_1'] = 1 \n",
    "df.loc[~(df['label'] ==2),'label_2'] = 0 \n",
    "df.loc[(df['label'] ==2),'label_2'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T05:28:07.607420Z",
     "start_time": "2021-04-20T05:28:06.289291Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from category_encoders import WOEEncoder \n",
    "enc = WOEEncoder(cols=class_list) \n",
    "df_label_0 = enc.fit_transform(df, df['label_0'])\n",
    "df_label_1 = enc.fit_transform(df, df['label_1'])\n",
    "df_label_2 = enc.fit_transform(df, df['label_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T05:28:48.544099Z",
     "start_time": "2021-04-20T05:28:48.517040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_bin</th>\n",
       "      <th>x_bin1</th>\n",
       "      <th>y_bin1</th>\n",
       "      <th>x_end</th>\n",
       "      <th>y_end</th>\n",
       "      <th>id</th>\n",
       "      <th>x_grid</th>\n",
       "      <th>y_grid</th>\n",
       "      <th>no_bin</th>\n",
       "      <th>dist_move_prev_bin_sen</th>\n",
       "      <th>v_bin_sen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.036669</td>\n",
       "      <td>5.149837</td>\n",
       "      <td>5.156617</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>6.165758</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>6.165758</td>\n",
       "      <td>6.165758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.479652</td>\n",
       "      <td>-1.226889</td>\n",
       "      <td>-1.226889</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-5.799020</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>-5.799020</td>\n",
       "      <td>-5.799020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.036669</td>\n",
       "      <td>5.149837</td>\n",
       "      <td>5.156617</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>6.165758</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>6.165758</td>\n",
       "      <td>6.165758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.037820</td>\n",
       "      <td>-1.226889</td>\n",
       "      <td>-1.226889</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-5.799020</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>-5.799020</td>\n",
       "      <td>-5.799020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036669</td>\n",
       "      <td>5.149837</td>\n",
       "      <td>5.156617</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>6.165758</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>-0.241137</td>\n",
       "      <td>6.165758</td>\n",
       "      <td>6.165758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2.299471</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>2.461990</td>\n",
       "      <td>2.461990</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>5.853137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2.140406</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>2.238846</td>\n",
       "      <td>2.238846</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>5.853137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2.299471</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>2.238846</td>\n",
       "      <td>2.238846</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>5.853137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2.916245</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>1.951164</td>\n",
       "      <td>1.951164</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>5.853137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>2.299471</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>1.545699</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>1.768843</td>\n",
       "      <td>1.768843</td>\n",
       "      <td>5.853137</td>\n",
       "      <td>5.853137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v_bin    x_bin1    y_bin1     x_end     y_end        id    x_grid  \\\n",
       "0    -0.036669  5.149837  5.156617 -0.000107 -0.000107  6.165758 -0.000107   \n",
       "1    -2.479652 -1.226889 -1.226889 -0.000107 -0.000107 -5.799020 -0.000107   \n",
       "2    -0.036669  5.149837  5.156617 -0.000107 -0.000107  6.165758 -0.000107   \n",
       "3    -2.037820 -1.226889 -1.226889 -0.000107 -0.000107 -5.799020 -0.000107   \n",
       "4    -0.036669  5.149837  5.156617 -0.000107 -0.000107  6.165758 -0.000107   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2996  2.299471  1.545699  1.545699 -0.000107 -0.000107  5.853137 -0.000107   \n",
       "2997  2.140406  1.545699  1.545699 -0.000107 -0.000107  5.853137 -0.000107   \n",
       "2998  2.299471  1.545699  1.545699 -0.000107 -0.000107  5.853137 -0.000107   \n",
       "2999  2.916245  1.545699  1.545699 -0.000107 -0.000107  5.853137 -0.000107   \n",
       "3000  2.299471  1.545699  1.545699 -0.000107 -0.000107  5.853137 -0.000107   \n",
       "\n",
       "        y_grid    no_bin  dist_move_prev_bin_sen  v_bin_sen  \n",
       "0    -0.241137 -0.241137                6.165758   6.165758  \n",
       "1    -0.241137 -0.241137               -5.799020  -5.799020  \n",
       "2    -0.241137 -0.241137                6.165758   6.165758  \n",
       "3    -0.241137 -0.241137               -5.799020  -5.799020  \n",
       "4    -0.241137 -0.241137                6.165758   6.165758  \n",
       "...        ...       ...                     ...        ...  \n",
       "2996  2.461990  2.461990                5.853137   5.853137  \n",
       "2997  2.238846  2.238846                5.853137   5.853137  \n",
       "2998  2.238846  2.238846                5.853137   5.853137  \n",
       "2999  1.951164  1.951164                5.853137   5.853137  \n",
       "3000  1.768843  1.768843                5.853137   5.853137  \n",
       "\n",
       "[3001 rows x 11 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_0[class_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:55:44.443697Z",
     "start_time": "2021-04-20T08:55:44.439896Z"
    }
   },
   "source": [
    "#### Weight of evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    代码摘自：https://github.com/Sundar0989/WOE-and-IV\n",
    "'''\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    " \n",
    "import pandas.core.algorithms as algos\n",
    "from pandas import Series\n",
    "import scipy.stats.stats as stats\n",
    "import re\n",
    "import traceback\n",
    "import string\n",
    "\n",
    "max_bin = 20\n",
    "force_bin = 3\n",
    "\n",
    "# define a binning function\n",
    "def mono_bin(Y, X, n = max_bin):\n",
    "    \n",
    "    df1      = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss  = df1[['X','Y']][df1.X.notnull()]\n",
    "    r        = 0\n",
    "    \n",
    "    while np.abs(r) < 1:\n",
    "        try:\n",
    "            d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n",
    "            d2 = d1.groupby('Bucket', as_index=True)\n",
    "            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "            n = n - 1 \n",
    "        except Exception as e:\n",
    "            n = n - 1\n",
    "\n",
    "    if len(d2) == 1:\n",
    "        n    = force_bin         \n",
    "        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n",
    "        if len(np.unique(bins)) == 2:\n",
    "            bins = np.insert(bins, 0, 1)\n",
    "            bins[1] = bins[1]-(bins[1]/2)\n",
    "        d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n",
    "        d2 = d1.groupby('Bucket', as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"MIN_VALUE\"] = d2.min().X\n",
    "    d3[\"MAX_VALUE\"] = d2.max().X\n",
    "    d3[\"COUNT\"]     = d2.count().Y\n",
    "    d3[\"EVENT\"]     = d2.sum().Y  # 正样本\n",
    "    d3[\"NONEVENT\"]  = d2.count().Y - d2.sum().Y # 负样本\n",
    "    d3              = d3.reset_index(drop=True)\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"]     = d3.EVENT/d3.COUNT       # 正样本类内百分比\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT    # 负样本类内百分比\n",
    "    \n",
    "    d3[\"DIST_EVENT\"]     = d3.EVENT/d3.sum().EVENT # 正的样本占所有正样本百分比\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT # 负的样本占所有负样本百分比\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    \n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def char_bin(Y, X):\n",
    "        \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]    \n",
    "    df2 = notmiss.groupby('X',as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"COUNT\"] = df2.count().Y\n",
    "    d3[\"MIN_VALUE\"] = df2.sum().Y.index\n",
    "    d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n",
    "    d3[\"EVENT\"] = df2.sum().Y\n",
    "    d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    d3 = d3.reset_index(drop=True)\n",
    "    \n",
    "    return(d3) \n",
    "\n",
    "\n",
    "def data_vars(df1, target):\n",
    "    \n",
    "    stack = traceback.extract_stack()\n",
    "    filename, lineno, function_name, code = stack[-2]\n",
    "    vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n",
    "    final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n",
    "    \n",
    "    x = df1.dtypes.index\n",
    "    count = -1\n",
    "    \n",
    "    for i in x:\n",
    "        if i.upper() not in (final.upper()):\n",
    "            if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n",
    "                conv = mono_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i\n",
    "                count = count + 1\n",
    "            else:\n",
    "                conv = char_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i            \n",
    "                count = count + 1\n",
    "                \n",
    "            if count == 0:\n",
    "                iv_df = conv\n",
    "            else:\n",
    "                iv_df = iv_df.append(conv,ignore_index=True)\n",
    "     \n",
    "    return iv_df \n",
    "# df = pd.read_csv('./data/bank.csv',sep=';')\n",
    "# dic = {'yes':1, 'no':0}\n",
    "# df['target'] = df['y'].map(dic)\n",
    "# df = df.drop('y',axis=1) \n",
    "\n",
    "final_iv = data_vars(df[class_list],df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 直方图编码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T05:48:41.841735Z",
     "start_time": "2021-04-20T05:48:41.831331Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def histogram_encoding(X,y):\n",
    "    category=list(set(X))\n",
    "    labels=list(set(y))\n",
    "    data=pd.concat([X,pd.DataFrame(y)],axis=1)\n",
    "    data.columns=['data','labels']\n",
    "    dictionary={}\n",
    "    for item in category:\n",
    "        temp=data[data['data']==item]\n",
    "        tp=temp['labels'].value_counts()\n",
    "        if tp.shape[0]<len(labels):\n",
    "            for label in labels:\n",
    "                if label not in tp.index:\n",
    "                    tp[label]=0\n",
    "        nums=tp.tolist()\n",
    "        sums=sum(nums)\n",
    "        nums=[items*1.0/sums for items in nums] ### 这里sums如果-1就是one leave out的分类问题形式\n",
    "        ##其实问题差别不是很大，数据量一般都是至少几十万的级别的这么一个数据点的删除与否没什么大影响\n",
    "        dictionary[item]=nums\n",
    "    hs_enc=X.copy()\n",
    "    hs_enc=hs_enc.values.tolist()\n",
    "    for i in range(len(hs_enc)):\n",
    "        hs_enc[i]=dictionary[hs_enc[i]]\n",
    "    return hs_enc,dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:58:46.880657Z",
     "start_time": "2021-04-20T07:58:46.870135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'x', 'y', 'v', 'dir', 'time', 'label', 'base_dis_diff', 'date',\n",
       "       'hour',\n",
       "       ...\n",
       "       '3y_str_2', '3y_str_3', '3y_str_4', '3y_str_5', '3y_str_6', '3y_str_7',\n",
       "       '3y_str_8', 'label_0', 'label_1', 'label_2'],\n",
       "      dtype='object', length=397)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:05:40.071072Z",
     "start_time": "2021-04-20T08:05:39.896646Z"
    }
   },
   "outputs": [],
   "source": [
    "hs_enc,dictionary = histogram_encoding(df[class_list[0]],df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:01:50.671322Z",
     "start_time": "2021-04-20T08:01:50.662590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hs_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### target 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:05:48.756051Z",
     "start_time": "2021-04-20T08:05:48.693342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3001 entries, 0 to 3000\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x       3001 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 126.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import *\n",
    "import pandas as pd\n",
    "# from sklearn.datasets import load_boston\n",
    "# bunch = load_boston()\n",
    "# y = bunch.target\n",
    "# X = pd.DataFrame(bunch.data, columns=bunch.feature_names)\n",
    "enc = TargetEncoder(cols=['x']).fit(df['x'],df['label'])\n",
    "numeric_dataset = enc.transform(df['x'])\n",
    "print(numeric_dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[特征编码方法总结—part1](https://www.zhihu.com/search?type=content&q=WOEEncoder)\n",
    "\n",
    "[Python - pandas - groupby+agg聚合重命名解决办法](https://blog.csdn.net/qq_24256877/article/details/108732042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
